{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen from the data manipulation and exploration, the non-alphabetical bigram are not very powerful discriminators. The following modelling process should exclude the non-alphabetical bigram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "os.chdir('/home/qc/Downloads/blueoptima/blueoptima_data/')\n",
    "sample_data = pd.read_csv('sample_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       ".cs      5000\n",
       ".java    5000\n",
       ".py      5000\n",
       "cpp      5000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.groupby('label')['label'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_process(data, ngram = 1, filter_status = 'all'):\n",
    "    import re\n",
    "#     from nltk.util import ngrams\n",
    "    gram = []\n",
    "    for rows in data:\n",
    "        if filter_status == 'alpha_only':\n",
    "            tokens = [token for token in rows.split(\" \") if (token != \"\" and token.isalpha())]\n",
    "        elif filter_status == 'non_alpha':\n",
    "            tokens = [token for token in rows.split(\" \") if (token != \"\" and not token.isalpha())]\n",
    "        else:\n",
    "            tokens = [token for token in rows.split(\" \") if token != \"\"]\n",
    "        n_grams = zip(*[tokens[i:] for i in range(ngram)])\n",
    "#         n_grams = list(ngrams(tokens, ngram))\n",
    "        \n",
    "#         n_grams = [re.sub(\"[(),']\", \"\", str(t)) for t in n_grams]\n",
    "        n_grams = [re.sub(\"['',]\", \"\", str(t)[2: -2]) for t in n_grams]\n",
    "        gram.append(n_grams) \n",
    "    return gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_fit(docs):\n",
    "    import numpy as np\n",
    "    from scipy.sparse import csr_matrix \n",
    "    indptr = [0]\n",
    "    indices = []\n",
    "    data = []\n",
    "    vocabulary = {}\n",
    "\n",
    "    for d in docs:\n",
    "        for term in d:\n",
    "            index = vocabulary.setdefault(term, len(vocabulary))\n",
    "            indices.append(index)\n",
    "            data.append(1)\n",
    "        indptr.append(len(indices))\n",
    "    return csr_matrix((data, indices, indptr), dtype = np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = sample_data['text'] \n",
    "y = sample_data['.java']\n",
    "indices = range(X.shape[0])\n",
    "X_train, X_test, y_train, y_test, train_index, test_index = train_test_split(X, y, indices, test_size=0.33, random_state=53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9603030303030303\n",
      "[[4722  220]\n",
      " [  42 1616]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8801742919389978, 0.9746682750301568]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#non-alphabetics unigram\n",
    "unigram_vectorizer = user_fit(ngram_process(X, filter_status = 'non_alpha'))\n",
    "\n",
    "user_count_train = unigram_vectorizer[train_index, :]\n",
    "user_count_test = unigram_vectorizer[test_index, :]\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Instantiate a Multinomial Naive Bayes classifier: nb_classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(user_count_train, y_train)\n",
    "\n",
    "# Create the predicted tags: pred\n",
    "pred = nb_classifier.predict(user_count_test)\n",
    " \n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=[0, 1])\n",
    "print(cm)\n",
    "\n",
    "[precision_score(y_test, pred), recall_score(y_test, pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8883388338833883, 0.9664871334530222]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# non-alphabetics cv\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "cross_pred =cross_val_predict(nb_classifier, user_count_train, y_train, cv = 10)\n",
    "[precision_score(y_train, cross_pred), recall_score(y_train, cross_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9778787878787879\n",
      "[[4820  122]\n",
      " [  24 1634]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9305239179954442, 0.985524728588661]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha-only unigram\n",
    "unigram_vectorizer = user_fit(ngram_process(X, filter_status = 'alpha_only'))\n",
    "\n",
    "user_count_train = unigram_vectorizer[train_index, :]\n",
    "user_count_test = unigram_vectorizer[test_index, :]\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Instantiate a Multinomial Naive Bayes classifier: nb_classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "nb_classifier.fit(user_count_train, y_train)\n",
    "\n",
    "# Create the predicted tags: pred\n",
    "pred = nb_classifier.predict(user_count_test)\n",
    " \n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=[0, 1])\n",
    "print(cm)\n",
    "\n",
    "[precision_score(y_test, pred), recall_score(y_test, pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9374288964732651, 0.9862357869539198]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "cross_pred =cross_val_predict(nb_classifier, user_count_train, y_train, cv = 10)\n",
    "[precision_score(y_train, cross_pred), recall_score(y_train, cross_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9831818181818182\n",
      "[[4863   79]\n",
      " [  32 1626]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9536656891495601, 0.9806996381182147]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all unigrams (non-alphabetical and alpha-only)\n",
    "unigram_vectorizer = user_fit(ngram_process(X))\n",
    "\n",
    "user_count_train = unigram_vectorizer[train_index, :]\n",
    "user_count_test = unigram_vectorizer[test_index, :]\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Instantiate a Multinomial Naive Bayes classifier: nb_classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(user_count_train, y_train)\n",
    "\n",
    "# Create the predicted tags: pred\n",
    "pred = nb_classifier.predict(user_count_test)\n",
    " \n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=[0, 1])\n",
    "print(cm)\n",
    "\n",
    "[precision_score(y_test, pred), recall_score(y_test, pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.952576112412178, 0.9736684619988031]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross validation\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "cross_pred =cross_val_predict(nb_classifier, user_count_train, y_train, cv = 10)\n",
    "[precision_score(y_train, cross_pred), recall_score(y_train, cross_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9966239710698345\n",
      "[[72009   247]\n",
      " [   20  6811]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9650042504958912, 0.9970721709852145]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha-only unigram and alpha-only bigram\n",
    "import scipy\n",
    "unigram_vectorizer = user_fit(ngram_process(X, ngram = 1, filter_status = 'alpha_only'))\n",
    "bigram_vectorizer = user_fit(ngram_process(X, ngram = 2, filter_status = 'alpha_only'))\n",
    "user_count = scipy.sparse.hstack((unigram_vectorizer, bigram_vectorizer)).tocsr()\n",
    "\n",
    "user_count_train = user_count[train_index,:]\n",
    "user_count_test = user_count[test_index, :]\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "\n",
    "# Instantiate a Multinomial Naive Bayes classifier: nb_classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(user_count_train, y_train)\n",
    "\n",
    "# Create the predicted tags: pred\n",
    "pred = nb_classifier.predict(user_count_test)\n",
    " \n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(score)\n",
    "\n",
    "# # Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=[0, 1])\n",
    "print(cm)\n",
    "\n",
    "[precision_score(y_test, pred), recall_score(y_test, pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9715539201811492, 0.9966608594657376]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha-only unigram and bigram cv\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "cross_pred =cross_val_predict(nb_classifier, user_count_train, y_train, cv = 10)\n",
    "[precision_score(y_train, cross_pred), recall_score(y_train, cross_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9856060606060606\n",
      "[[4864   78]\n",
      " [  17 1641]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9546247818499127, 0.9897466827503015]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all unigrams and alpha-only bigram\n",
    "import scipy\n",
    "unigram_vectorizer = user_fit(ngram_process(X))\n",
    "bigram_vectorizer = user_fit(ngram_process(X, ngram = 2, filter_status = 'alpha_only'))\n",
    "user_count = scipy.sparse.hstack((unigram_vectorizer, bigram_vectorizer)).tocsr()\n",
    "\n",
    "user_count_train = user_count[train_index,:]\n",
    "user_count_test = user_count[test_index, :]\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "\n",
    "# Instantiate a Multinomial Naive Bayes classifier: nb_classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(user_count_train, y_train)\n",
    "\n",
    "# Create the predicted tags: pred\n",
    "pred = nb_classifier.predict(user_count_test)\n",
    " \n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(score)\n",
    "\n",
    "# # Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=[0, 1])\n",
    "print(cm)\n",
    "\n",
    "[precision_score(y_test, pred), recall_score(y_test, pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9715539201811492, 0.9966608594657376]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha-only unigram and bigram cv\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "cross_pred =cross_val_predict(nb_classifier, user_count_train, y_train, cv = 10)\n",
    "[precision_score(y_train, cross_pred), recall_score(y_train, cross_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9956060606060606\n",
      "[[4931   11]\n",
      " [  18 1640]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9933373712901272, 0.9891435464414958]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha-only using sklearn CountVectorizer\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "cross_pred =cross_val_predict(nb_classifier, user_count_train, y_train, cv = 10)\n",
    "[precision_score(y_train, cross_pred), recall_score(y_train, cross_pred)]\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "count_vectorizer = CountVectorizer(analyzer= 'word')\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Instantiate a Multinomial Naive Bayes classifier: nb_classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(count_train, y_train)\n",
    "\n",
    "# Create the predicted tags: pred\n",
    "pred = nb_classifier.predict(count_test)\n",
    " \n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=[0, 1])\n",
    "print(cm)\n",
    "\n",
    "[precision_score(y_test, pred), recall_score(y_test, pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9563445867287543, 0.983243566726511]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha-only cv\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "cross_pred =cross_val_predict(nb_classifier, user_count_train, y_train, cv = 10)\n",
    "[precision_score(y_train, cross_pred), recall_score(y_train, cross_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9972727272727273\n",
      "[[4940    2]\n",
      " [  16 1642]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9987834549878345, 0.9903498190591074]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha-only and alpha-only bigram\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "count_vectorizer = CountVectorizer(analyzer= 'word', ngram_range=[1, 2])\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Instantiate a Multinomial Naive Bayes classifier: nb_classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(count_train, y_train)\n",
    "\n",
    "# Create the predicted tags: pred\n",
    "pred = nb_classifier.predict(count_test)\n",
    " \n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=[0, 1])\n",
    "print(cm)\n",
    "\n",
    "[precision_score(y_test, pred), recall_score(y_test, pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.95276266819353, 0.9958108916816277]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "cross_pred =cross_val_predict(nb_classifier, count_train, y_train, cv = 10)\n",
    "[precision_score(y_train, cross_pred), recall_score(y_train, cross_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using full (truncated) data set now.\n",
    "import os\n",
    "import pandas as pd\n",
    "os.chdir('/home/qc/Downloads/blueoptima/blueoptima_data/')\n",
    "final_data = pd.read_csv('final_trunc_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       ".cs       86995\n",
       ".java    119902\n",
       ".py       20607\n",
       "cpp       12153\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.groupby('label')['label'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X = final_data['text'] \n",
    "y = final_data['.java']\n",
    "indices = range(X.shape[0])\n",
    "X_train, X_test, y_train, y_test, train_index, test_index = train_test_split(X, y, indices, test_size=0.33, random_state=53)\n",
    "\n",
    "count_vectorizer = CountVectorizer(analyzer= 'word')\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9975596494999178\n",
      "[[39545    52]\n",
      " [  141 39349]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9986802365422197, 0.9964294758166624]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Instantiate a Multinomial Naive Bayes classifier: nb_classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(count_train, y_train)\n",
    "\n",
    "# Create the predicted tags: pred\n",
    "pred = nb_classifier.predict(count_test)\n",
    " \n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=[0, 1])\n",
    "print(cm)\n",
    "\n",
    "[precision_score(y_test, pred), recall_score(y_test, pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.998032501089596, 0.9967044719693579]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "cross_pred =cross_val_predict(nb_classifier, count_train, y_train, cv = 10)\n",
    "[precision_score(y_train, cross_pred), recall_score(y_train, cross_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qc/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998862012720169\n",
      "[[39591     6]\n",
      " [   84 39406]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9998477621029128, 0.9978728792099265]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Instantiate a random forest classifier: rf_classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=53)\n",
    "rf_classifier.fit(count_train, y_train)\n",
    "\n",
    "# Create the predicted tags: pred\n",
    "pred = rf_classifier.predict(count_test)\n",
    " \n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=[0, 1])\n",
    "print(cm)\n",
    "\n",
    "[precision_score(y_test, pred), recall_score(y_test, pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9999377102279806, 0.9981719146396061]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "cross_pred =cross_val_predict(rf_classifier, count_train, y_train, cv = 10)\n",
    "[precision_score(y_train, cross_pred), recall_score(y_train, cross_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.993083566199249\n",
      "[[39518    79]\n",
      " [  468 39022]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9979795913148002, 0.9881488984553052]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Instantiate a support vector machine classifier: svm_classifier\n",
    "svm_classifier = SVC(random_state=53, gamma='scale')\n",
    "svm_classifier.fit(count_train, y_train)\n",
    "\n",
    "# Create the predicted tags: pred\n",
    "pred = svm_classifier.predict(count_test)\n",
    " \n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=[0, 1])\n",
    "print(cm)\n",
    "\n",
    "[precision_score(y_test, pred), recall_score(y_test, pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "cross_pred =cross_val_predict(svm_classifier, count_train, y_train, cv = 10)\n",
    "[precision_score(y_train, cross_pred), recall_score(y_train, cross_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qc/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/qc/.local/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9989505228419335\n",
      "[[39554    43]\n",
      " [   40 39450]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9989111994530676, 0.9989870853380602]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Instantiate a logistic classifier: lr_classifier\n",
    "lr_classifier = LogisticRegression(random_state=53)\n",
    "lr_classifier.fit(count_train, y_train)\n",
    "\n",
    "# Create the predicted tags: pred\n",
    "pred = lr_classifier.predict(count_test)\n",
    " \n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=[0, 1])\n",
    "print(cm)\n",
    "\n",
    "[precision_score(y_test, pred), recall_score(y_test, pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qc/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/qc/.local/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.999377776671603, 0.9986942247425757]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "cross_pred =cross_val_predict(lr_classifier, count_train, y_train, cv = 10)\n",
    "[precision_score(y_train, cross_pred), recall_score(y_train, cross_pred)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of pure interest, multinomial naive bayesian is also used to predict other coding languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9978504684714302\n",
      "[[50215   134]\n",
      " [   36 28702]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9953530309335553, 0.9987473032222145]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X = final_data['text'] \n",
    "y = final_data['.cs']\n",
    "indices = range(X.shape[0])\n",
    "X_train, X_test, y_train, y_test, train_index, test_index = train_test_split(X, y, indices, test_size=0.33, random_state=53)\n",
    "\n",
    "count_vectorizer = CountVectorizer(analyzer= 'word')\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Instantiate a Multinomial Naive Bayes classifier: nb_classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "nb_classifier.fit(count_train, y_train)\n",
    "\n",
    "# Create the predicted tags: pred\n",
    "pred = nb_classifier.predict(count_test)\n",
    " \n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=[0, 1])\n",
    "print(cm)\n",
    "\n",
    "[precision_score(y_test, pred), recall_score(y_test, pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9976608039247917\n",
      "[[74887   172]\n",
      " [   13  4015]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.958920468115596, 0.996772591857001]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X = final_data['text'] \n",
    "y = final_data['cpp']\n",
    "indices = range(X.shape[0])\n",
    "X_train, X_test, y_train, y_test, train_index, test_index = train_test_split(X, y, indices, test_size=0.33, random_state=53)\n",
    "\n",
    "count_vectorizer = CountVectorizer(analyzer= 'word')\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Instantiate a Multinomial Naive Bayes classifier: nb_classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "nb_classifier.fit(count_train, y_train)\n",
    "\n",
    "# Create the predicted tags: pred\n",
    "pred = nb_classifier.predict(count_test)\n",
    " \n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=[0, 1])\n",
    "print(cm)\n",
    "\n",
    "[precision_score(y_test, pred), recall_score(y_test, pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9991781202978998\n",
      "[[72198    58]\n",
      " [    7  6824]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.991572217378669, 0.998975259844825]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X = final_data['text'] \n",
    "y = final_data['.py']\n",
    "indices = range(X.shape[0])\n",
    "X_train, X_test, y_train, y_test, train_index, test_index = train_test_split(X, y, indices, test_size=0.33, random_state=53)\n",
    "\n",
    "count_vectorizer = CountVectorizer(analyzer= 'word')\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Instantiate a Multinomial Naive Bayes classifier: nb_classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "nb_classifier.fit(count_train, y_train)\n",
    "\n",
    "# Create the predicted tags: pred\n",
    "pred = nb_classifier.predict(count_test)\n",
    " \n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=[0, 1])\n",
    "print(cm)\n",
    "\n",
    "[precision_score(y_test, pred), recall_score(y_test, pred)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial NB seems to make more mistakes in terms of false positives, we therefore try to use random forest classifier to improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qc/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9993424962383198\n",
      "[[50325    24]\n",
      " [   28 28710]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9991647525579453, 0.9990256802839446]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X = final_data['text'] \n",
    "y = final_data['.cs']\n",
    "indices = range(X.shape[0])\n",
    "X_train, X_test, y_train, y_test, train_index, test_index = train_test_split(X, y, indices, test_size=0.33, random_state=53)\n",
    "\n",
    "count_vectorizer = CountVectorizer(analyzer= 'word')\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Instantiate a random forest classifier: rf_classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=53)\n",
    "\n",
    "rf_classifier.fit(count_train, y_train)\n",
    "\n",
    "# Create the predicted tags: pred\n",
    "pred = rf_classifier.predict(count_test)\n",
    " \n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=[0, 1])\n",
    "print(cm)\n",
    "\n",
    "[precision_score(y_test, pred), recall_score(y_test, pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qc/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998596482354875\n",
      "[[75058     1]\n",
      " [  110  3918]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.999744832865527, 0.9726911618669315]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X = final_data['text'] \n",
    "y = final_data['cpp']\n",
    "indices = range(X.shape[0])\n",
    "X_train, X_test, y_train, y_test, train_index, test_index = train_test_split(X, y, indices, test_size=0.33, random_state=53)\n",
    "\n",
    "count_vectorizer = CountVectorizer(analyzer= 'word')\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Instantiate a random forest classifier: rf_classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=53)\n",
    "\n",
    "rf_classifier.fit(count_train, y_train)\n",
    "\n",
    "# Create the predicted tags: pred\n",
    "pred = rf_classifier.predict(count_test)\n",
    " \n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=[0, 1])\n",
    "print(cm)\n",
    "\n",
    "[precision_score(y_test, pred), recall_score(y_test, pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qc/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9985459051424381\n",
      "[[72251     5]\n",
      " [  110  6721]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9992566161165626, 0.9838969404186796]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X = final_data['text'] \n",
    "y = final_data['.py']\n",
    "indices = range(X.shape[0])\n",
    "X_train, X_test, y_train, y_test, train_index, test_index = train_test_split(X, y, indices, test_size=0.33, random_state=53)\n",
    "\n",
    "count_vectorizer = CountVectorizer(analyzer= 'word')\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Instantiate a random forest classifier: rf_classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=53)\n",
    "\n",
    "rf_classifier.fit(count_train, y_train)\n",
    "\n",
    "# Create the predicted tags: pred\n",
    "pred = rf_classifier.predict(count_test)\n",
    " \n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=[0, 1])\n",
    "print(cm)\n",
    "\n",
    "[precision_score(y_test, pred), recall_score(y_test, pred)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False Positives are greatly reduced using random forest classifier in the trade of an increase in false negatives however."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
