{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a call_center exercise. Through this exercise, we want to find out which agent can approach the customers most efficiently (interested in the deal) and also which type of customer is more inclined to be interested in the deal given their characteristic features, i.e. age, working sector and residential region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all related modules from Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure data files and the program file are saved in the same directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_path = os.path.abspath('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load calls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calls_data = pd.read_csv(notebook_path + '\\\\calls.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a quick look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phone Number</th>\n",
       "      <th>Call Outcome</th>\n",
       "      <th>Agent</th>\n",
       "      <th>Call Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4934</th>\n",
       "      <td>86974920</td>\n",
       "      <td>CALL BACK LATER</td>\n",
       "      <td>red</td>\n",
       "      <td>4934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3398</th>\n",
       "      <td>293076903</td>\n",
       "      <td>NOT INTERESTED</td>\n",
       "      <td>orange</td>\n",
       "      <td>3398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2443</th>\n",
       "      <td>296668016</td>\n",
       "      <td>CALL BACK LATER</td>\n",
       "      <td>red</td>\n",
       "      <td>2443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2543</th>\n",
       "      <td>296668016</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>black</td>\n",
       "      <td>2543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2343</th>\n",
       "      <td>296668016</td>\n",
       "      <td>CALL BACK LATER</td>\n",
       "      <td>orange</td>\n",
       "      <td>2343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4053</th>\n",
       "      <td>330347320</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>orange</td>\n",
       "      <td>4053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953</th>\n",
       "      <td>330347320</td>\n",
       "      <td>CALL BACK LATER</td>\n",
       "      <td>red</td>\n",
       "      <td>3953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>457146043</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>orange</td>\n",
       "      <td>1473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>457146043</td>\n",
       "      <td>CALL BACK LATER</td>\n",
       "      <td>red</td>\n",
       "      <td>1373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4545</th>\n",
       "      <td>832669152</td>\n",
       "      <td>NOT INTERESTED</td>\n",
       "      <td>red</td>\n",
       "      <td>4545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4445</th>\n",
       "      <td>832669152</td>\n",
       "      <td>CALL BACK LATER</td>\n",
       "      <td>orange</td>\n",
       "      <td>4445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3191</th>\n",
       "      <td>913330936</td>\n",
       "      <td>NOT INTERESTED</td>\n",
       "      <td>red</td>\n",
       "      <td>3191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>1068208068</td>\n",
       "      <td>ANSWER MACHINE</td>\n",
       "      <td>orange</td>\n",
       "      <td>1441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>1068208068</td>\n",
       "      <td>NOT INTERESTED</td>\n",
       "      <td>orange</td>\n",
       "      <td>1541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1317965432</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>orange</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>1491024555</td>\n",
       "      <td>NOT INTERESTED</td>\n",
       "      <td>red</td>\n",
       "      <td>572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>1491024555</td>\n",
       "      <td>CALL BACK LATER</td>\n",
       "      <td>orange</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>1491024555</td>\n",
       "      <td>CALL BACK LATER</td>\n",
       "      <td>orange</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1590010071</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>green</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>1990092541</td>\n",
       "      <td>CALL BACK LATER</td>\n",
       "      <td>red</td>\n",
       "      <td>1971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Phone Number     Call Outcome   Agent  Call Number\n",
       "4934      86974920  CALL BACK LATER     red         4934\n",
       "3398     293076903   NOT INTERESTED  orange         3398\n",
       "2443     296668016  CALL BACK LATER     red         2443\n",
       "2543     296668016       INTERESTED   black         2543\n",
       "2343     296668016  CALL BACK LATER  orange         2343\n",
       "4053     330347320       INTERESTED  orange         4053\n",
       "3953     330347320  CALL BACK LATER     red         3953\n",
       "1473     457146043       INTERESTED  orange         1473\n",
       "1373     457146043  CALL BACK LATER     red         1373\n",
       "4545     832669152   NOT INTERESTED     red         4545\n",
       "4445     832669152  CALL BACK LATER  orange         4445\n",
       "3191     913330936   NOT INTERESTED     red         3191\n",
       "1441    1068208068   ANSWER MACHINE  orange         1441\n",
       "1541    1068208068   NOT INTERESTED  orange         1541\n",
       "197     1317965432       INTERESTED  orange          197\n",
       "572     1491024555   NOT INTERESTED     red          572\n",
       "372     1491024555  CALL BACK LATER  orange          372\n",
       "472     1491024555  CALL BACK LATER  orange          472\n",
       "11      1590010071       INTERESTED   green           11\n",
       "1971    1990092541  CALL BACK LATER     red         1971"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calls_data.sort_values('Phone Number').head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which agent makes most callsï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Agent\n",
       "orange    2234\n",
       "red       1478\n",
       "black      750\n",
       "green      339\n",
       "blue       199\n",
       "Name: Agent, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calls_data.groupby('Agent')['Agent'].count().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent 'orange' apparently has far more calls made than others. But we are not sure whether he made a lot of useless calls or he called the customers effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among all leads received at least one call from us, we want to find how many calls we need to make in order for them to make a decision (sign up or not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.839587932303164"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calls_data.groupby('Phone Number')['Phone Number'].count().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could merge the two data sets between leads (customer characteristic file) and calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_data = pd.read_csv(notebook_path + '\\\\leads.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Phone Number</th>\n",
       "      <th>Region</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Isabela MEZA</td>\n",
       "      <td>175718505368</td>\n",
       "      <td>north-west</td>\n",
       "      <td>wholesale</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Deangelo LEE</td>\n",
       "      <td>937521423043</td>\n",
       "      <td>north-west</td>\n",
       "      <td>retail</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rosia MENDEZ</td>\n",
       "      <td>403640999962</td>\n",
       "      <td>midlands</td>\n",
       "      <td>agriculture</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jeremiah GALLOWAY</td>\n",
       "      <td>946740713605</td>\n",
       "      <td>scotland</td>\n",
       "      <td>food</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sarah POPE</td>\n",
       "      <td>264176984341</td>\n",
       "      <td>midlands</td>\n",
       "      <td>retail</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nolan VILLANUEVA</td>\n",
       "      <td>102993220908</td>\n",
       "      <td>north-west</td>\n",
       "      <td>wholesale</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wade AVERY</td>\n",
       "      <td>936057266681</td>\n",
       "      <td>south-west</td>\n",
       "      <td>construction</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Karyn SHEPARD</td>\n",
       "      <td>416050061466</td>\n",
       "      <td>midlands</td>\n",
       "      <td>retail</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Buster CALDERON</td>\n",
       "      <td>169044176823</td>\n",
       "      <td>south-west</td>\n",
       "      <td>food</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lu JACOBSON</td>\n",
       "      <td>477236163516</td>\n",
       "      <td>north-west</td>\n",
       "      <td>consultancy</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name  Phone Number      Region        Sector  Age\n",
       "0       Isabela MEZA  175718505368  north-west     wholesale   19\n",
       "1       Deangelo LEE  937521423043  north-west        retail   38\n",
       "2       Rosia MENDEZ  403640999962    midlands   agriculture   40\n",
       "3  Jeremiah GALLOWAY  946740713605    scotland          food   23\n",
       "4         Sarah POPE  264176984341    midlands        retail   18\n",
       "5   Nolan VILLANUEVA  102993220908  north-west     wholesale   35\n",
       "6         Wade AVERY  936057266681  south-west  construction   20\n",
       "7      Karyn SHEPARD  416050061466    midlands        retail   60\n",
       "8    Buster CALDERON  169044176823  south-west          food   21\n",
       "9        Lu JACOBSON  477236163516  north-west   consultancy   28"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leads_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_calls_left = pd.merge(leads_data, calls_data, how = 'left', on = 'Phone Number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Phone Number</th>\n",
       "      <th>Region</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Age</th>\n",
       "      <th>Call Outcome</th>\n",
       "      <th>Agent</th>\n",
       "      <th>Call Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6905</th>\n",
       "      <td>Aaliyah STOKES</td>\n",
       "      <td>829695501942</td>\n",
       "      <td>north-east</td>\n",
       "      <td>retail</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5745</th>\n",
       "      <td>Aaron MICHAEL</td>\n",
       "      <td>718889280723</td>\n",
       "      <td>north-west</td>\n",
       "      <td>consultancy</td>\n",
       "      <td>24</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>blue</td>\n",
       "      <td>4125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>Abagail KENT</td>\n",
       "      <td>518447025746</td>\n",
       "      <td>midlands</td>\n",
       "      <td>food</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7568</th>\n",
       "      <td>Abagail PACE</td>\n",
       "      <td>647443547151</td>\n",
       "      <td>midlands</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>40</td>\n",
       "      <td>CALL BACK LATER</td>\n",
       "      <td>green</td>\n",
       "      <td>2484.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7570</th>\n",
       "      <td>Abagail PACE</td>\n",
       "      <td>647443547151</td>\n",
       "      <td>midlands</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>40</td>\n",
       "      <td>NOT INTERESTED</td>\n",
       "      <td>orange</td>\n",
       "      <td>2684.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7569</th>\n",
       "      <td>Abagail PACE</td>\n",
       "      <td>647443547151</td>\n",
       "      <td>midlands</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>40</td>\n",
       "      <td>CALL BACK LATER</td>\n",
       "      <td>green</td>\n",
       "      <td>2584.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8130</th>\n",
       "      <td>Abagail SHAFFER</td>\n",
       "      <td>118266780799</td>\n",
       "      <td>south</td>\n",
       "      <td>construction</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8329</th>\n",
       "      <td>Abbey BLANKENSHIP</td>\n",
       "      <td>96746535702</td>\n",
       "      <td>south</td>\n",
       "      <td>food</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9906</th>\n",
       "      <td>Abbey BROWNING</td>\n",
       "      <td>143802021855</td>\n",
       "      <td>north-east</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5003</th>\n",
       "      <td>Abbey SALAS</td>\n",
       "      <td>41832516768</td>\n",
       "      <td>scotland</td>\n",
       "      <td>consultancy</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5223</th>\n",
       "      <td>Abbey TERRELL</td>\n",
       "      <td>967742850061</td>\n",
       "      <td>south-west</td>\n",
       "      <td>wholesale</td>\n",
       "      <td>45</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>red</td>\n",
       "      <td>380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5281</th>\n",
       "      <td>Abby ARROYO</td>\n",
       "      <td>59001151830</td>\n",
       "      <td>scotland</td>\n",
       "      <td>construction</td>\n",
       "      <td>75</td>\n",
       "      <td>NOT INTERESTED</td>\n",
       "      <td>orange</td>\n",
       "      <td>4336.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9185</th>\n",
       "      <td>Abby KAISER</td>\n",
       "      <td>387967420978</td>\n",
       "      <td>wales</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11688</th>\n",
       "      <td>Abby KRAUSE</td>\n",
       "      <td>8171288142</td>\n",
       "      <td>south-east</td>\n",
       "      <td>food</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Abby STRICKLAND</td>\n",
       "      <td>172518708468</td>\n",
       "      <td>south-west</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>83</td>\n",
       "      <td>NOT INTERESTED</td>\n",
       "      <td>orange</td>\n",
       "      <td>3139.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Abby STRICKLAND</td>\n",
       "      <td>172518708468</td>\n",
       "      <td>south-west</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>83</td>\n",
       "      <td>ANSWER MACHINE</td>\n",
       "      <td>orange</td>\n",
       "      <td>3039.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>Abdul CRAWFORD</td>\n",
       "      <td>530813048122</td>\n",
       "      <td>south</td>\n",
       "      <td>retail</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9764</th>\n",
       "      <td>Abdul LOWE</td>\n",
       "      <td>551294792414</td>\n",
       "      <td>scotland</td>\n",
       "      <td>consultancy</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4923</th>\n",
       "      <td>Abdul SLOAN</td>\n",
       "      <td>119791699392</td>\n",
       "      <td>north-west</td>\n",
       "      <td>food</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5195</th>\n",
       "      <td>Abdullah MCINTYRE</td>\n",
       "      <td>889301083876</td>\n",
       "      <td>northern-ireland</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>23</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>orange</td>\n",
       "      <td>1871.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name  Phone Number            Region         Sector  Age  \\\n",
       "6905      Aaliyah STOKES  829695501942        north-east         retail   44   \n",
       "5745       Aaron MICHAEL  718889280723        north-west    consultancy   24   \n",
       "871         Abagail KENT  518447025746          midlands           food   20   \n",
       "7568        Abagail PACE  647443547151          midlands  entertainment   40   \n",
       "7570        Abagail PACE  647443547151          midlands  entertainment   40   \n",
       "7569        Abagail PACE  647443547151          midlands  entertainment   40   \n",
       "8130     Abagail SHAFFER  118266780799             south   construction   32   \n",
       "8329   Abbey BLANKENSHIP   96746535702             south           food   28   \n",
       "9906      Abbey BROWNING  143802021855        north-east  entertainment   40   \n",
       "5003         Abbey SALAS   41832516768          scotland    consultancy   43   \n",
       "5223       Abbey TERRELL  967742850061        south-west      wholesale   45   \n",
       "5281         Abby ARROYO   59001151830          scotland   construction   75   \n",
       "9185         Abby KAISER  387967420978             wales  entertainment   28   \n",
       "11688        Abby KRAUSE    8171288142        south-east           food   18   \n",
       "251      Abby STRICKLAND  172518708468        south-west  entertainment   83   \n",
       "250      Abby STRICKLAND  172518708468        south-west  entertainment   83   \n",
       "1713      Abdul CRAWFORD  530813048122             south         retail   21   \n",
       "9764          Abdul LOWE  551294792414          scotland    consultancy   22   \n",
       "4923         Abdul SLOAN  119791699392        north-west           food   24   \n",
       "5195   Abdullah MCINTYRE  889301083876  northern-ireland  entertainment   23   \n",
       "\n",
       "          Call Outcome   Agent  Call Number  \n",
       "6905               NaN     NaN          NaN  \n",
       "5745        INTERESTED    blue       4125.0  \n",
       "871                NaN     NaN          NaN  \n",
       "7568   CALL BACK LATER   green       2484.0  \n",
       "7570    NOT INTERESTED  orange       2684.0  \n",
       "7569   CALL BACK LATER   green       2584.0  \n",
       "8130               NaN     NaN          NaN  \n",
       "8329               NaN     NaN          NaN  \n",
       "9906               NaN     NaN          NaN  \n",
       "5003               NaN     NaN          NaN  \n",
       "5223        INTERESTED     red        380.0  \n",
       "5281    NOT INTERESTED  orange       4336.0  \n",
       "9185               NaN     NaN          NaN  \n",
       "11688              NaN     NaN          NaN  \n",
       "251     NOT INTERESTED  orange       3139.0  \n",
       "250     ANSWER MACHINE  orange       3039.0  \n",
       "1713               NaN     NaN          NaN  \n",
       "9764               NaN     NaN          NaN  \n",
       "4923               NaN     NaN          NaN  \n",
       "5195        INTERESTED  orange       1871.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leads_calls_left.sort_values('Name').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.839587932303164"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leads_calls_left[leads_calls_left['Call Outcome'].notnull()].groupby('Name')['Name'].count().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focusing on the signed up leads only, calculate the average calls they received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = pd.merge(calls_data, leads_data, on = 'Phone Number')\n",
    "signups_data = pd.read_csv(notebook_path + '\\\\signups.csv')\n",
    "signups_leads_calls = pd.merge(temp_data, signups_data, left_on = 'Name', right_on = 'Lead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phone Number</th>\n",
       "      <th>Call Outcome</th>\n",
       "      <th>Agent</th>\n",
       "      <th>Call Number</th>\n",
       "      <th>Region</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Age</th>\n",
       "      <th>Lead</th>\n",
       "      <th>Approval Decision</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aaron MICHAEL</th>\n",
       "      <td>718889280723</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>blue</td>\n",
       "      <td>4125</td>\n",
       "      <td>north-west</td>\n",
       "      <td>consultancy</td>\n",
       "      <td>24</td>\n",
       "      <td>Aaron MICHAEL</td>\n",
       "      <td>REJECTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abbey TERRELL</th>\n",
       "      <td>967742850061</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>red</td>\n",
       "      <td>380</td>\n",
       "      <td>south-west</td>\n",
       "      <td>wholesale</td>\n",
       "      <td>45</td>\n",
       "      <td>Abbey TERRELL</td>\n",
       "      <td>REJECTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abigail BOYLE</th>\n",
       "      <td>882003542264</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>red</td>\n",
       "      <td>2017</td>\n",
       "      <td>south-west</td>\n",
       "      <td>consultancy</td>\n",
       "      <td>71</td>\n",
       "      <td>Abigail BOYLE</td>\n",
       "      <td>REJECTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ada CISNEROS</th>\n",
       "      <td>583848516870</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>orange</td>\n",
       "      <td>2031</td>\n",
       "      <td>north-west</td>\n",
       "      <td>food</td>\n",
       "      <td>63</td>\n",
       "      <td>Ada CISNEROS</td>\n",
       "      <td>REJECTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Admiral SOLOMON</th>\n",
       "      <td>480425059761</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>red</td>\n",
       "      <td>1937</td>\n",
       "      <td>north-west</td>\n",
       "      <td>retail</td>\n",
       "      <td>25</td>\n",
       "      <td>Admiral SOLOMON</td>\n",
       "      <td>APPROVED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adolf SALAZAR</th>\n",
       "      <td>163178719806</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>orange</td>\n",
       "      <td>228</td>\n",
       "      <td>north-west</td>\n",
       "      <td>retail</td>\n",
       "      <td>19</td>\n",
       "      <td>Adolf SALAZAR</td>\n",
       "      <td>APPROVED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adolph ZUNIGA</th>\n",
       "      <td>76223398562</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>orange</td>\n",
       "      <td>917</td>\n",
       "      <td>northern-ireland</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>24</td>\n",
       "      <td>Adolph ZUNIGA</td>\n",
       "      <td>REJECTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adrianna GARRETT</th>\n",
       "      <td>388295208858</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>green</td>\n",
       "      <td>235</td>\n",
       "      <td>scotland</td>\n",
       "      <td>food</td>\n",
       "      <td>18</td>\n",
       "      <td>Adrianna GARRETT</td>\n",
       "      <td>REJECTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adrianne MCMAHON</th>\n",
       "      <td>557948543615</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>orange</td>\n",
       "      <td>3069</td>\n",
       "      <td>north-west</td>\n",
       "      <td>food</td>\n",
       "      <td>30</td>\n",
       "      <td>Adrianne MCMAHON</td>\n",
       "      <td>APPROVED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adrienne OROZCO</th>\n",
       "      <td>655413695089</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>black</td>\n",
       "      <td>3248</td>\n",
       "      <td>south</td>\n",
       "      <td>food</td>\n",
       "      <td>37</td>\n",
       "      <td>Adrienne OROZCO</td>\n",
       "      <td>APPROVED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agatha SANDOVAL</th>\n",
       "      <td>123910429544</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>red</td>\n",
       "      <td>417</td>\n",
       "      <td>north-west</td>\n",
       "      <td>consultancy</td>\n",
       "      <td>23</td>\n",
       "      <td>Agatha SANDOVAL</td>\n",
       "      <td>REJECTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aggie ROGERS</th>\n",
       "      <td>461739379189</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>black</td>\n",
       "      <td>2659</td>\n",
       "      <td>midlands</td>\n",
       "      <td>agriculture</td>\n",
       "      <td>83</td>\n",
       "      <td>Aggie ROGERS</td>\n",
       "      <td>REJECTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agustin JACKSON</th>\n",
       "      <td>886046329289</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>orange</td>\n",
       "      <td>3855</td>\n",
       "      <td>north-west</td>\n",
       "      <td>retail</td>\n",
       "      <td>22</td>\n",
       "      <td>Agustin JACKSON</td>\n",
       "      <td>REJECTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ahmad BOONE</th>\n",
       "      <td>548086321841</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>black</td>\n",
       "      <td>3633</td>\n",
       "      <td>midlands</td>\n",
       "      <td>consultancy</td>\n",
       "      <td>22</td>\n",
       "      <td>Ahmad BOONE</td>\n",
       "      <td>REJECTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ahmed SCHAEFER</th>\n",
       "      <td>876403847928</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>orange</td>\n",
       "      <td>4392</td>\n",
       "      <td>wales</td>\n",
       "      <td>consultancy</td>\n",
       "      <td>66</td>\n",
       "      <td>Ahmed SCHAEFER</td>\n",
       "      <td>REJECTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Akeem BATES</th>\n",
       "      <td>420466720149</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>green</td>\n",
       "      <td>594</td>\n",
       "      <td>north-west</td>\n",
       "      <td>retail</td>\n",
       "      <td>43</td>\n",
       "      <td>Akeem BATES</td>\n",
       "      <td>REJECTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alba COSTA</th>\n",
       "      <td>876348729078</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>red</td>\n",
       "      <td>4870</td>\n",
       "      <td>south</td>\n",
       "      <td>consultancy</td>\n",
       "      <td>24</td>\n",
       "      <td>Alba COSTA</td>\n",
       "      <td>REJECTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aldo MOSS</th>\n",
       "      <td>265494534487</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>orange</td>\n",
       "      <td>1739</td>\n",
       "      <td>south-east</td>\n",
       "      <td>wholesale</td>\n",
       "      <td>23</td>\n",
       "      <td>Aldo MOSS</td>\n",
       "      <td>REJECTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alexander SHIELDS</th>\n",
       "      <td>479990438826</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>green</td>\n",
       "      <td>1949</td>\n",
       "      <td>north-west</td>\n",
       "      <td>retail</td>\n",
       "      <td>45</td>\n",
       "      <td>Alexander SHIELDS</td>\n",
       "      <td>REJECTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alfred CASTRO</th>\n",
       "      <td>734283335286</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>orange</td>\n",
       "      <td>4593</td>\n",
       "      <td>south-west</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>27</td>\n",
       "      <td>Alfred CASTRO</td>\n",
       "      <td>APPROVED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Phone Number Call Outcome   Agent  Call Number  \\\n",
       "Name                                                                \n",
       "Aaron MICHAEL      718889280723   INTERESTED    blue         4125   \n",
       "Abbey TERRELL      967742850061   INTERESTED     red          380   \n",
       "Abigail BOYLE      882003542264   INTERESTED     red         2017   \n",
       "Ada CISNEROS       583848516870   INTERESTED  orange         2031   \n",
       "Admiral SOLOMON    480425059761   INTERESTED     red         1937   \n",
       "Adolf SALAZAR      163178719806   INTERESTED  orange          228   \n",
       "Adolph ZUNIGA       76223398562   INTERESTED  orange          917   \n",
       "Adrianna GARRETT   388295208858   INTERESTED   green          235   \n",
       "Adrianne MCMAHON   557948543615   INTERESTED  orange         3069   \n",
       "Adrienne OROZCO    655413695089   INTERESTED   black         3248   \n",
       "Agatha SANDOVAL    123910429544   INTERESTED     red          417   \n",
       "Aggie ROGERS       461739379189   INTERESTED   black         2659   \n",
       "Agustin JACKSON    886046329289   INTERESTED  orange         3855   \n",
       "Ahmad BOONE        548086321841   INTERESTED   black         3633   \n",
       "Ahmed SCHAEFER     876403847928   INTERESTED  orange         4392   \n",
       "Akeem BATES        420466720149   INTERESTED   green          594   \n",
       "Alba COSTA         876348729078   INTERESTED     red         4870   \n",
       "Aldo MOSS          265494534487   INTERESTED  orange         1739   \n",
       "Alexander SHIELDS  479990438826   INTERESTED   green         1949   \n",
       "Alfred CASTRO      734283335286   INTERESTED  orange         4593   \n",
       "\n",
       "                             Region         Sector  Age               Lead  \\\n",
       "Name                                                                         \n",
       "Aaron MICHAEL            north-west    consultancy   24      Aaron MICHAEL   \n",
       "Abbey TERRELL            south-west      wholesale   45      Abbey TERRELL   \n",
       "Abigail BOYLE            south-west    consultancy   71      Abigail BOYLE   \n",
       "Ada CISNEROS             north-west           food   63       Ada CISNEROS   \n",
       "Admiral SOLOMON          north-west         retail   25    Admiral SOLOMON   \n",
       "Adolf SALAZAR            north-west         retail   19      Adolf SALAZAR   \n",
       "Adolph ZUNIGA      northern-ireland  entertainment   24      Adolph ZUNIGA   \n",
       "Adrianna GARRETT           scotland           food   18   Adrianna GARRETT   \n",
       "Adrianne MCMAHON         north-west           food   30   Adrianne MCMAHON   \n",
       "Adrienne OROZCO               south           food   37    Adrienne OROZCO   \n",
       "Agatha SANDOVAL          north-west    consultancy   23    Agatha SANDOVAL   \n",
       "Aggie ROGERS               midlands    agriculture   83       Aggie ROGERS   \n",
       "Agustin JACKSON          north-west         retail   22    Agustin JACKSON   \n",
       "Ahmad BOONE                midlands    consultancy   22        Ahmad BOONE   \n",
       "Ahmed SCHAEFER                wales    consultancy   66     Ahmed SCHAEFER   \n",
       "Akeem BATES              north-west         retail   43        Akeem BATES   \n",
       "Alba COSTA                    south    consultancy   24         Alba COSTA   \n",
       "Aldo MOSS                south-east      wholesale   23          Aldo MOSS   \n",
       "Alexander SHIELDS        north-west         retail   45  Alexander SHIELDS   \n",
       "Alfred CASTRO            south-west  entertainment   27      Alfred CASTRO   \n",
       "\n",
       "                  Approval Decision  \n",
       "Name                                 \n",
       "Aaron MICHAEL              REJECTED  \n",
       "Abbey TERRELL              REJECTED  \n",
       "Abigail BOYLE              REJECTED  \n",
       "Ada CISNEROS               REJECTED  \n",
       "Admiral SOLOMON            APPROVED  \n",
       "Adolf SALAZAR              APPROVED  \n",
       "Adolph ZUNIGA              REJECTED  \n",
       "Adrianna GARRETT           REJECTED  \n",
       "Adrianne MCMAHON           APPROVED  \n",
       "Adrienne OROZCO            APPROVED  \n",
       "Agatha SANDOVAL            REJECTED  \n",
       "Aggie ROGERS               REJECTED  \n",
       "Agustin JACKSON            REJECTED  \n",
       "Ahmad BOONE                REJECTED  \n",
       "Ahmed SCHAEFER             REJECTED  \n",
       "Akeem BATES                REJECTED  \n",
       "Alba COSTA                 REJECTED  \n",
       "Aldo MOSS                  REJECTED  \n",
       "Alexander SHIELDS          REJECTED  \n",
       "Alfred CASTRO              APPROVED  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signups_leads_calls.groupby('Name').last().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0989583333333335"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signups_leads_calls.groupby('Lead')['Lead'].count().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check whether the last deciding call per lead always ends up with Call Outcome == INTERESTED\n",
    "temp = signups_leads_calls.groupby('Name').last()\n",
    "temp[temp['Call Outcome'] != 'INTERESTED'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check whether each lead has several Call Outcome == INTERESTED\n",
    "temp1 = calls_data[calls_data['Call Outcome'] == 'INTERESTED'].groupby(['Phone Number']).count()\n",
    "temp1[temp1['Call Outcome'] > 1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out which agent has most signups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Agent\n",
       "red       316\n",
       "orange    284\n",
       "green      67\n",
       "blue       52\n",
       "black      49\n",
       "Name: Agent, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We filter by 'INTERESTED' in order to only keep the last call that make the lead sign up.\n",
    "temp.groupby('Agent')['Agent'].count().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to see that although Agent Orange made most calls, Agent red got most of the signups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the above conclusion is based on the assumption that all agents called same type of leads. This is an over-restrictive assumption. For example, Agent red may be just lucky to call leads who are more likely to sign up based on their characteristic variables. \n",
    "\n",
    "Note also that not necessarily those leads who are interested will sign up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Phone Number</th>\n",
       "      <th>Region</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Age</th>\n",
       "      <th>Call Outcome</th>\n",
       "      <th>Agent</th>\n",
       "      <th>Call Number</th>\n",
       "      <th>Lead</th>\n",
       "      <th>Approval Decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deangelo LEE</td>\n",
       "      <td>937521423043</td>\n",
       "      <td>north-west</td>\n",
       "      <td>retail</td>\n",
       "      <td>38</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>orange</td>\n",
       "      <td>2413.0</td>\n",
       "      <td>Deangelo LEE</td>\n",
       "      <td>APPROVED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Lu JACOBSON</td>\n",
       "      <td>477236163516</td>\n",
       "      <td>north-west</td>\n",
       "      <td>consultancy</td>\n",
       "      <td>28</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>orange</td>\n",
       "      <td>2149.0</td>\n",
       "      <td>Lu JACOBSON</td>\n",
       "      <td>REJECTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Theron WELCH</td>\n",
       "      <td>533788208390</td>\n",
       "      <td>north-east</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>36</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>green</td>\n",
       "      <td>1207.0</td>\n",
       "      <td>Theron WELCH</td>\n",
       "      <td>APPROVED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lilia OCHOA</td>\n",
       "      <td>80967872849</td>\n",
       "      <td>north-west</td>\n",
       "      <td>wholesale</td>\n",
       "      <td>33</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>black</td>\n",
       "      <td>1333.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Cheryle CALDWELL</td>\n",
       "      <td>484404817049</td>\n",
       "      <td>north-west</td>\n",
       "      <td>consultancy</td>\n",
       "      <td>27</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>orange</td>\n",
       "      <td>473.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Naoma DURHAM</td>\n",
       "      <td>940509676942</td>\n",
       "      <td>south-east</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>30</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>black</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>Naoma DURHAM</td>\n",
       "      <td>REJECTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Alyssa HAMPTON</td>\n",
       "      <td>593981680906</td>\n",
       "      <td>north-east</td>\n",
       "      <td>consultancy</td>\n",
       "      <td>27</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>orange</td>\n",
       "      <td>2292.0</td>\n",
       "      <td>Alyssa HAMPTON</td>\n",
       "      <td>REJECTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Glen PATTON</td>\n",
       "      <td>532155164354</td>\n",
       "      <td>midlands</td>\n",
       "      <td>food</td>\n",
       "      <td>20</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>red</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>Glen PATTON</td>\n",
       "      <td>APPROVED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Christena KRAMER</td>\n",
       "      <td>379624957194</td>\n",
       "      <td>scotland</td>\n",
       "      <td>food</td>\n",
       "      <td>32</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>orange</td>\n",
       "      <td>4067.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Bonnie CALLAHAN</td>\n",
       "      <td>350965802992</td>\n",
       "      <td>scotland</td>\n",
       "      <td>food</td>\n",
       "      <td>27</td>\n",
       "      <td>INTERESTED</td>\n",
       "      <td>red</td>\n",
       "      <td>1753.0</td>\n",
       "      <td>Bonnie CALLAHAN</td>\n",
       "      <td>APPROVED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name  Phone Number      Region         Sector  Age  \\\n",
       "3        Deangelo LEE  937521423043  north-west         retail   38   \n",
       "12        Lu JACOBSON  477236163516  north-west    consultancy   28   \n",
       "16       Theron WELCH  533788208390  north-east  entertainment   36   \n",
       "19        Lilia OCHOA   80967872849  north-west      wholesale   33   \n",
       "31   Cheryle CALDWELL  484404817049  north-west    consultancy   27   \n",
       "36       Naoma DURHAM  940509676942  south-east  entertainment   30   \n",
       "56     Alyssa HAMPTON  593981680906  north-east    consultancy   27   \n",
       "72        Glen PATTON  532155164354    midlands           food   20   \n",
       "88   Christena KRAMER  379624957194    scotland           food   32   \n",
       "101   Bonnie CALLAHAN  350965802992    scotland           food   27   \n",
       "\n",
       "    Call Outcome   Agent  Call Number             Lead Approval Decision  \n",
       "3     INTERESTED  orange       2413.0     Deangelo LEE          APPROVED  \n",
       "12    INTERESTED  orange       2149.0      Lu JACOBSON          REJECTED  \n",
       "16    INTERESTED   green       1207.0     Theron WELCH          APPROVED  \n",
       "19    INTERESTED   black       1333.0              NaN               NaN  \n",
       "31    INTERESTED  orange        473.0              NaN               NaN  \n",
       "36    INTERESTED   black       2013.0     Naoma DURHAM          REJECTED  \n",
       "56    INTERESTED  orange       2292.0   Alyssa HAMPTON          REJECTED  \n",
       "72    INTERESTED     red       2400.0      Glen PATTON          APPROVED  \n",
       "88    INTERESTED  orange       4067.0              NaN               NaN  \n",
       "101   INTERESTED     red       1753.0  Bonnie CALLAHAN          APPROVED  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signups_leads_calls_all = pd.merge(leads_calls_left, signups_data, how = 'left', left_on = 'Name', right_on = 'Lead')\n",
    "signups_leads_calls_all[signups_leads_calls_all['Call Outcome'] == 'INTERESTED'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are cases where an Agent has successfully made a lead interested but the lead didn't sign up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to check which agent tends to have the highest signups/calls ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Agent\n",
       "blue      0.261307\n",
       "red       0.213802\n",
       "green     0.197640\n",
       "orange    0.127126\n",
       "black     0.065333\n",
       "Name: Agent, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer to the most calls question\n",
    "calls_per_agent = calls_data.groupby('Agent')['Agent'].count().sort_index()\n",
    "# answer to the most signups question\n",
    "signups_per_agent = signups_leads_calls.groupby('Lead').last().groupby('Agent')['Agent'].count().sort_index()\n",
    "# divide between the two and sort it\n",
    "signups_rate = (signups_per_agent/calls_per_agent).sort_values(ascending = False)\n",
    "signups_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can just include those final actual conversational calls (neither a deadline nor answer machine) each agent made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Agent\n",
       "blue      0.290503\n",
       "red       0.238491\n",
       "green     0.219672\n",
       "orange    0.140873\n",
       "black     0.074130\n",
       "Name: Agent, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_calls_per_agent = calls_data[(calls_data['Call Outcome'] != 'DEADLINE') & (calls_data['Call Outcome'] != 'ANSWER MACHINE')].groupby('Agent')['Agent'].count()\n",
    "actual_signups_rate = (signups_per_agent/actual_calls_per_agent).sort_values(ascending = False)\n",
    "actual_signups_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although Agent blue has the highest signups/calls ratio, he only made 199 calls in total, not even one tenth of the Agent orange, and he only made 52 signups, far less than those of Agent red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to check whether the variation of average signups/calls ratio is statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chi-square test can be used to test whether signups count is uniformlly distributed. Firstly we need to create a contingency table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signups count</th>\n",
       "      <th>calls count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agent</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>black</th>\n",
       "      <td>49</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blue</th>\n",
       "      <td>52</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>green</th>\n",
       "      <td>67</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orange</th>\n",
       "      <td>284</td>\n",
       "      <td>2234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>red</th>\n",
       "      <td>316</td>\n",
       "      <td>1478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        signups count  calls count\n",
       "Agent                             \n",
       "black              49          750\n",
       "blue               52          199\n",
       "green              67          339\n",
       "orange            284         2234\n",
       "red               316         1478"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.concat([signups_per_agent, calls_per_agent], axis = 1)\n",
    "test_data.columns = ['signups count', 'calls count']\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our bare eye we can see that the distribution of the ratio of signups against non-signups count is disproportioinal. \n",
    "We can prove this by running chi-square test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88.97471726636842, 2.1740841509211066e-18)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I use list comprehension to decompose the dataframe into separate row vector.\n",
    "chi2, p, dof, expected = stats.chi2_contingency([i for i in np.array(test_data)])\n",
    "chi2, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86.62269161071926, 6.8649353770441634e-18)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I need to change the code here\n",
    "test_data = pd.concat([signups_per_agent, actual_calls_per_agent], axis = 1)\n",
    "test_data.columns = ['signups count', 'actual calls count']\n",
    "chi2, p, dof, expected = stats.chi2_contingency([i for i in np.array(test_data)])\n",
    "chi2, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the p-value we can see that the variability between the agents signups per call is statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we dig into the characteristic features of leads and try to firstly find out leads from which region are more likely to be interested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Region\n",
       "north-west          365\n",
       "south-west          161\n",
       "midlands            150\n",
       "north-east          139\n",
       "scotland            137\n",
       "south-east          136\n",
       "south                62\n",
       "london               56\n",
       "wales                50\n",
       "northern-ireland     40\n",
       "Name: Region, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leads_calls_inner = pd.merge(calls_data, leads_data, how = 'inner', on = 'Phone Number')\n",
    "leadsOrderByRegion = leads_calls_inner[leads_calls_inner['Call Outcome'] == 'INTERESTED'].groupby('Region')['Region'].count().sort_values(ascending = False)\n",
    "leadsOrderByRegion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that leads from north-west are more likely to be interested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then we can find out leads from which sector are more likely to be interested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sector\n",
       "consultancy      301\n",
       "retail           290\n",
       "food             261\n",
       "wholesale        233\n",
       "entertainment    135\n",
       "construction      46\n",
       "agriculture       30\n",
       "Name: Sector, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leadsOrderBySector = leads_calls_inner[leads_calls_inner['Call Outcome'] == 'INTERESTED'].groupby('Sector')['Sector'].count().sort_values(ascending = False)\n",
    "leadsOrderBySector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that leads from consultancy sector are more likely to be interested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given leads who have expressed interests and signed up, we want to find out leads from which region are more likely to be approved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Region\n",
       "north-west          0.452381\n",
       "scotland            0.451220\n",
       "south               0.375000\n",
       "south-east          0.337209\n",
       "midlands            0.285714\n",
       "northern-ireland    0.250000\n",
       "south-west          0.245098\n",
       "north-east          0.243902\n",
       "wales               0.147059\n",
       "london              0.080000\n",
       "Name: Region, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use signups_leads_calls for this purpose since data included only covers those leads who have signed up.\n",
    "signups_leads_calls_clean = signups_leads_calls[signups_leads_calls['Call Outcome'] == 'INTERESTED']\n",
    "signups_per_region = signups_leads_calls_clean.groupby('Region')['Region'].count().sort_index()\n",
    "approved_per_region = signups_leads_calls_clean[signups_leads_calls_clean['Approval Decision'] == 'APPROVED'].groupby('Region')['Region'].count().sort_index()\n",
    "(approved_per_region/signups_per_region).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that leads from north-west region are more likely to be approved and the difference in approval rate is large across different regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run the same Chi-square test to see whether such difference is statistically different as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20.50334600413018, 0.015047849853946683)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.concat([approved_per_region, signups_per_region], axis = 1)\n",
    "chi2, p, dof, expected = stats.chi2_contingency(test_data)\n",
    "chi2, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variation in approved rate is statistically significant across different regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to build up a forecasting model for signups by firstly including the three characteristic features, i.e. age, region and sector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are only interested in the calls that got a call outcome as 'INTERESTED' or 'NOT INTERESTED'. \n",
    "# 'ANSWER MACHINE', 'CALL BACK LATER' are unfinished calls; 'DEAD LINE' does not reflect any characteristic features by nature.\n",
    "in_sample = signups_leads_calls_all[(signups_leads_calls_all['Call Outcome'] == 'INTERESTED') | (signups_leads_calls_all['Call Outcome'] == 'NOT INTERESTED')]\n",
    "temp_data = pd.merge(calls_data, leads_data, on = 'Phone Number', how = 'right')\n",
    "out_sample = temp_data[temp_data['Call Outcome'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a data transformation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def data_pipeline(data, selected_cols, target_index, char_cols, char_orders, mapper):\n",
    "    data = data.loc[:, selected_cols]\n",
    "    for index, char_col in enumerate(char_cols):\n",
    "        cat_type = CategoricalDtype(categories = char_orders[index], ordered = True)\n",
    "        data[char_col] = data[char_col].astype(cat_type).values\n",
    "        data = data.join(pd.get_dummies(data[char_col]))\n",
    "#         To reduce the right skewness of variable 'Age' \n",
    "        data['Age'] = np.log(data['Age'])\n",
    "    target_col = data[selected_cols[target_index]].map(mapper)\n",
    "    data.insert(0, 'target', target_col)\n",
    "    data = data.drop(selected_cols[target_index], axis = 1)\n",
    "    data = data.drop(char_cols, axis = 1)\n",
    "    data = data.reset_index(drop = True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st step modelling\n",
    "in_sample_vars = ['Call Outcome', 'Age', 'Sector', 'Region']\n",
    "out_sample_vars = ['Phone Number', 'Name', 'Age', 'Sector', 'Region']\n",
    "char_col =  ['Region', 'Sector']\n",
    "char_order = [leadsOrderByRegion.index, leadsOrderBySector.index]\n",
    "in_sample_mapper = {'INTERESTED':1, 'NOT INTERESTED':0}\n",
    "out_sample_mapper = {}\n",
    "\n",
    "final_in_sample = data_pipeline(in_sample, in_sample_vars, 0, char_col, char_order, in_sample_mapper)\n",
    "final_out_sample = data_pipeline(out_sample, out_sample_vars, 0, char_col, char_order, out_sample_mapper)\n",
    "X_out_sample = final_out_sample.iloc[:, 2:]\n",
    "\n",
    "train_set, test_set = train_test_split(final_in_sample, test_size = 0.2, random_state = 42)\n",
    "train_set = train_set.reset_index(drop = True)\n",
    "test_set = test_set.reset_index(drop = True)\n",
    "\n",
    "X_train = train_set.iloc[:, 1:]\n",
    "Y_train = train_set.iloc[:, 0]\n",
    "X_test = test_set.iloc[:, 1:]\n",
    "Y_test = test_set.iloc[:, 0]\n",
    "X_full = final_in_sample.iloc[:, 1:]\n",
    "Y_full = final_in_sample.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<bound method BaseEstimator.get_params of LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=50, solver='liblinear',\n",
       "           tol=0.0001, verbose=0, warm_start=False)>,\n",
       " <bound method BaseEstimator.get_params of LogisticRegression(C=0.06951927961775606, class_weight=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "           multi_class='warn', n_jobs=None, penalty='l2', random_state=50,\n",
       "           solver='liblinear', tol=0.0001, verbose=0, warm_start=False)>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Fine tunning Logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "LogR = LogisticRegression(solver= 'liblinear', random_state=50)\n",
    "\n",
    "param_grid = {\n",
    "     'penalty' : ['l1', 'l2'],\n",
    "    'C' : np.logspace(-2, 2, 20),\n",
    "    'class_weight': ['balanced', None],\n",
    "    'solver' : ['liblinear']}\n",
    "\n",
    "temp = LogisticRegression(random_state = 50)\n",
    "grid_search = GridSearchCV(temp, param_grid, cv = 10)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "aug_LogR = grid_search.best_estimator_\n",
    "[LogR.get_params, aug_LogR.get_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   22.4s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  2.4min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, auc, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "RandForest = RandomForestClassifier(n_estimators=100, random_state = 50)\n",
    "\n",
    "temp = RandomForestClassifier(random_state = 50)\n",
    "param_grid = {'n_estimators': [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)],\n",
    "               'max_features': ['auto', 'sqrt'],\n",
    "               'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)],\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "               'min_samples_leaf': [1, 2, 4],\n",
    "               'bootstrap': [True, False]}\n",
    "\n",
    "random_grid = RandomizedSearchCV(estimator = temp, param_distributions = param_grid, n_iter = 50, cv = 5, verbose=2, random_state=50, n_jobs = -1)\n",
    "random_grid.fit(X_train, Y_train)\n",
    "aug_RandForest = random_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<bound method BaseEstimator.get_params of RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "             oob_score=False, random_state=50, verbose=0, warm_start=False)>,\n",
       " <bound method BaseEstimator.get_params of RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=70, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=4, min_samples_split=10,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=600, n_jobs=None,\n",
       "             oob_score=False, random_state=50, verbose=0, warm_start=False)>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[RandForest.get_params, aug_RandForest.get_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "GBM = GradientBoostingClassifier(subsample = 0.8, max_depth = 5, min_samples_split= 15, max_features = 'sqrt', random_state = 50)\n",
    "KNN = KNeighborsClassifier(n_neighbors = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.37793425,  0.60914159,  0.4363232 , -0.60425131, -0.18617069,\n",
       "         -0.23387347,  0.01194474, -0.14904875,  1.48598785, -0.6606915 ,\n",
       "         -0.22735238,  0.86291872, -0.52371939,  0.02080468,  0.59466066,\n",
       "          0.28335261, -0.70892056, -0.04708746]]),\n",
       " array([[-0.0477804 ,  0.52818561,  0.34995491, -0.49218562, -0.12430482,\n",
       "         -0.16943933,  0.01937853, -0.08930823,  0.63646746, -0.42475767,\n",
       "         -0.10705501,  0.66343909, -0.52368232, -0.05267253,  0.42250993,\n",
       "          0.1706423 , -0.50025654, -0.05304409]])]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict = {'logistic' : LogR, \n",
    "        'tuned logistic' : aug_LogR, \n",
    "        'random forest' : RandForest, \n",
    "        'tuned random forest' : aug_RandForest,\n",
    "        'GBM': GBM,\n",
    "        'KNN': KNN}\n",
    "\n",
    "validation_dict = {'precision' : precision_score,\n",
    "                  'recall' : recall_score,\n",
    "                  'f1_score': f1_score}\n",
    "\n",
    "for key in model_dict:\n",
    "    model_dict[key].fit(X_train, Y_train)\n",
    "\n",
    "[LogR.coef_, aug_LogR.coef_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to generate modelling performance metrics\n",
    "def output_table(model_f, val_f, X, Y, pred_f = None):\n",
    "    out = []\n",
    "    for key1 in model_f.keys():\n",
    "        if pred_f == None:\n",
    "            Y_predict = model_f[key1].predict(X)\n",
    "        else:\n",
    "            Y_predict = pred_f(model_f[key1], X, Y, cv = 10)\n",
    "        for key2 in val_f.keys():\n",
    "            out.append(val_f[key2](Y, Y_predict))\n",
    "    cols = len(val_f)\n",
    "    rows = len(model_f)\n",
    "    out = np.array(out)\n",
    "    out.shape = (rows, cols)\n",
    "    out = pd.DataFrame(out, index=model_f.keys(), columns=val_f.keys())\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic</th>\n",
       "      <td>0.651445</td>\n",
       "      <td>0.668260</td>\n",
       "      <td>0.659745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuned logistic</th>\n",
       "      <td>0.647215</td>\n",
       "      <td>0.699809</td>\n",
       "      <td>0.672485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>0.590020</td>\n",
       "      <td>0.576482</td>\n",
       "      <td>0.583172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuned random forest</th>\n",
       "      <td>0.627181</td>\n",
       "      <td>0.652964</td>\n",
       "      <td>0.639813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBM</th>\n",
       "      <td>0.627630</td>\n",
       "      <td>0.655832</td>\n",
       "      <td>0.641421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.612695</td>\n",
       "      <td>0.636711</td>\n",
       "      <td>0.624473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     precision    recall  f1_score\n",
       "logistic              0.651445  0.668260  0.659745\n",
       "tuned logistic        0.647215  0.699809  0.672485\n",
       "random forest         0.590020  0.576482  0.583172\n",
       "tuned random forest   0.627181  0.652964  0.639813\n",
       "GBM                   0.627630  0.655832  0.641421\n",
       "KNN                   0.612695  0.636711  0.624473"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can have a look at the modelling performance of all four models in the training sample\n",
    "output_table(model_dict, validation_dict, X_train, Y_train, cross_val_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic</th>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.654206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuned logistic</th>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.660617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.603774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuned random forest</th>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.609023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBM</th>\n",
       "      <td>0.576271</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.623853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.581132</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.598058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     precision  recall  f1_score\n",
       "logistic              0.614035   0.700  0.654206\n",
       "tuned logistic        0.604651   0.728  0.660617\n",
       "random forest         0.571429   0.640  0.603774\n",
       "tuned random forest   0.574468   0.648  0.609023\n",
       "GBM                   0.576271   0.680  0.623853\n",
       "KNN                   0.581132   0.616  0.598058"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can have a look at the forecasting performance of four models in the test sample\n",
    "output_table(model_dict, validation_dict, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function mapping predicted probability to precision\n",
    "def prob_precision(model, X, Y, prob_range):\n",
    "    precision = []\n",
    "    for prob in prob_range:\n",
    "        Y_prob = pd.DataFrame(model.predict_proba(X))\n",
    "        selected_index = Y_prob.index[Y_prob[1] > prob].tolist()\n",
    "        Y_selected = Y[selected_index]\n",
    "        TP = len(Y_selected[Y_selected == 1])\n",
    "        FP = len(Y_selected[Y_selected == 0])\n",
    "        precision.append(TP/(TP + FP))\n",
    "    out = pd.concat([pd.DataFrame(prob_range), pd.DataFrame(precision)], axis = 1)\n",
    "    out.columns = ['proba', 'precision']\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proba</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.660395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.682022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.694132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.698217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.717666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.729167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.735211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.751701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.756881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.782353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.784314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    proba  precision\n",
       "0    0.50   0.660395\n",
       "1    0.53   0.682022\n",
       "2    0.56   0.694132\n",
       "3    0.59   0.698217\n",
       "4    0.62   0.717666\n",
       "5    0.65   0.729167\n",
       "6    0.68   0.735211\n",
       "7    0.71   0.751701\n",
       "8    0.74   0.756881\n",
       "9    0.77   0.782353\n",
       "10   0.80   0.784314"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_precision(LogR, X_train, Y_train, np.linspace(.5, .8, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proba</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.614035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.647826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.673267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.673203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.709402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.755814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.808511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.794118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    proba  precision\n",
       "0    0.50   0.614035\n",
       "1    0.53   0.647826\n",
       "2    0.56   0.673267\n",
       "3    0.59   0.687500\n",
       "4    0.62   0.673203\n",
       "5    0.65   0.709402\n",
       "6    0.68   0.755814\n",
       "7    0.71   0.746479\n",
       "8    0.74   0.785714\n",
       "9    0.77   0.808511\n",
       "10   0.80   0.794118"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_precision(LogR, X_test, Y_test, np.linspace(.5, .8, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_out_sample_prob = pd.DataFrame(LogR.predict_proba(X_out_sample))\n",
    "X_out_sample_selected_index = Y_out_sample_prob.index[Y_out_sample_prob[1] > .68].tolist()\n",
    "X_out_sample = X_out_sample.reset_index(drop=True)\n",
    "X_out_sample_1st = X_out_sample.iloc[X_out_sample_selected_index, ].reset_index(drop = True)\n",
    "final_out_sample_1st = final_out_sample.iloc[X_out_sample_selected_index, ].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd step modelling starts\n",
    "in_sample = signups_leads_calls_all[(signups_leads_calls_all['Call Outcome'] == 'INTERESTED')]\n",
    "in_sample_vars = ['Approval Decision', 'Age', 'Sector', 'Region']\n",
    "out_sample_vars = ['Phone Number','Name', 'Age', 'Sector', 'Region']\n",
    "char_col =  ['Region', 'Sector']\n",
    "char_order = [leadsOrderByRegion.index, leadsOrderBySector.index]\n",
    "in_sample_mapper = {'APPROVED':1, 'REJECTED':1, None:0}\n",
    "out_sample_mapper = {}\n",
    "\n",
    "final_in_sample = data_pipeline(in_sample, in_sample_vars, 0, char_col, char_order, in_sample_mapper)\n",
    "final_out_sample = data_pipeline(out_sample, out_sample_vars, 0, char_col, char_order, out_sample_mapper)\n",
    "\n",
    "train_set, test_set = train_test_split(final_in_sample, test_size = 0.2, random_state = 42)\n",
    "train_set = train_set.reset_index(drop = True)\n",
    "test_set = test_set.reset_index(drop = True)\n",
    "X_train = train_set.iloc[:, 1:]\n",
    "Y_train = train_set.iloc[:, 0]\n",
    "X_test = test_set.iloc[:, 1:]\n",
    "Y_test = test_set.iloc[:, 0]\n",
    "X_full = final_in_sample.iloc[:, 1:]\n",
    "Y_full = final_in_sample.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<bound method BaseEstimator.get_params of LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=50, solver='liblinear',\n",
       "           tol=0.0001, verbose=0, warm_start=False)>,\n",
       " <bound method BaseEstimator.get_params of LogisticRegression(C=0.06951927961775606, class_weight=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "           multi_class='warn', n_jobs=None, penalty='l2', random_state=50,\n",
       "           solver='liblinear', tol=0.0001, verbose=0, warm_start=False)>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogR_2nd = LogisticRegression(solver= 'liblinear', random_state=50)\n",
    "\n",
    "param_grid = {\n",
    "     'penalty' : ['l1', 'l2'],\n",
    "    'C' : np.logspace(-2, 2, 20),\n",
    "    'class_weight': ['balanced', None],\n",
    "    'solver' : ['liblinear']}\n",
    "temp = LogisticRegression(random_state = 50)\n",
    "grid_search = GridSearchCV(temp, param_grid, cv = 10)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "aug_LogR_2nd = grid_search.best_estimator_\n",
    "[LogR_2nd.get_params, aug_LogR_2nd.get_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  1.5min finished\n"
     ]
    }
   ],
   "source": [
    "RandForest_2nd = RandomForestClassifier(n_estimators=100, random_state = 50)\n",
    "\n",
    "temp = RandomForestClassifier(random_state = 50)\n",
    "param_grid = {'n_estimators': [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)],\n",
    "               'max_features': ['auto', 'sqrt'],\n",
    "               'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)],\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "               'min_samples_leaf': [1, 2, 4],\n",
    "               'bootstrap': [True, False]}\n",
    "\n",
    "random_grid = RandomizedSearchCV(estimator = temp, param_distributions = param_grid, n_iter = 50, cv = 5, verbose=2, random_state = 50, n_jobs = -1)\n",
    "random_grid.fit(X_train, Y_train)\n",
    "aug_RandForest_2nd = random_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "GBM_2nd = GradientBoostingClassifier(subsample = 0.8, max_depth = 5, min_samples_split= 10, max_features = 'sqrt', random_state = 50)\n",
    "KNN_2nd = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict_2nd = {'logistic 2nd' : LogR_2nd, \n",
    "        'tuned logistic 2nd' : aug_LogR_2nd, \n",
    "        'random forest 2nd' : RandForest_2nd, \n",
    "        'tuned random 2nd' : aug_RandForest_2nd,\n",
    "        'GBM 2nd': GBM_2nd,\n",
    "        'KNN 2nd': KNN_2nd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic 2nd</th>\n",
       "      <td>0.602911</td>\n",
       "      <td>0.933977</td>\n",
       "      <td>0.732786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuned logistic 2nd</th>\n",
       "      <td>0.602172</td>\n",
       "      <td>0.982287</td>\n",
       "      <td>0.746634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest 2nd</th>\n",
       "      <td>0.596899</td>\n",
       "      <td>0.619968</td>\n",
       "      <td>0.608215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuned random 2nd</th>\n",
       "      <td>0.606178</td>\n",
       "      <td>0.758454</td>\n",
       "      <td>0.673820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBM 2nd</th>\n",
       "      <td>0.601036</td>\n",
       "      <td>0.747182</td>\n",
       "      <td>0.666188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN 2nd</th>\n",
       "      <td>0.595273</td>\n",
       "      <td>0.648953</td>\n",
       "      <td>0.620955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    precision    recall  f1_score\n",
       "logistic 2nd         0.602911  0.933977  0.732786\n",
       "tuned logistic 2nd   0.602172  0.982287  0.746634\n",
       "random forest 2nd    0.596899  0.619968  0.608215\n",
       "tuned random 2nd     0.606178  0.758454  0.673820\n",
       "GBM 2nd              0.601036  0.747182  0.666188\n",
       "KNN 2nd              0.595273  0.648953  0.620955"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_table(model_dict_2nd, validation_dict, X_train, Y_train, cross_val_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic 2nd</th>\n",
       "      <td>0.567797</td>\n",
       "      <td>0.911565</td>\n",
       "      <td>0.699739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuned logistic 2nd</th>\n",
       "      <td>0.572000</td>\n",
       "      <td>0.972789</td>\n",
       "      <td>0.720403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest 2nd</th>\n",
       "      <td>0.585987</td>\n",
       "      <td>0.625850</td>\n",
       "      <td>0.605263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuned random 2nd</th>\n",
       "      <td>0.597938</td>\n",
       "      <td>0.789116</td>\n",
       "      <td>0.680352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBM 2nd</th>\n",
       "      <td>0.563830</td>\n",
       "      <td>0.721088</td>\n",
       "      <td>0.632836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN 2nd</th>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.625850</td>\n",
       "      <td>0.599349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    precision    recall  f1_score\n",
       "logistic 2nd         0.567797  0.911565  0.699739\n",
       "tuned logistic 2nd   0.572000  0.972789  0.720403\n",
       "random forest 2nd    0.585987  0.625850  0.605263\n",
       "tuned random 2nd     0.597938  0.789116  0.680352\n",
       "GBM 2nd              0.563830  0.721088  0.632836\n",
       "KNN 2nd              0.575000  0.625850  0.599349"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in model_dict_2nd:\n",
    "    model_dict_2nd[key].fit(X_train, Y_train)\n",
    "    \n",
    "output_table(model_dict_2nd, validation_dict, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proba</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.604374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.605817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.613851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.639503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.649682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.681529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.691700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.732673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.735294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    proba  precision\n",
       "0    0.50   0.604374\n",
       "1    0.52   0.605817\n",
       "2    0.54   0.613851\n",
       "3    0.56   0.639503\n",
       "4    0.58   0.649682\n",
       "5    0.60   0.651042\n",
       "6    0.62   0.681529\n",
       "7    0.64   0.691700\n",
       "8    0.66   0.732673\n",
       "9    0.68   0.735294\n",
       "10   0.70   0.666667"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_precision(aug_LogR_2nd, X_train, Y_train, np.linspace(.5, .7, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215            Dedra ADKINS\n",
       "402          Pennie MURILLO\n",
       "1147            Lars RITTER\n",
       "1060             Neil MEYER\n",
       "272       Alexandra HAMMOND\n",
       "1192            Doris SCOTT\n",
       "23               Gage HOUSE\n",
       "1027            Marco OLSON\n",
       "1263            Sal HERRING\n",
       "876           Tia ARMSTRONG\n",
       "952          Omer MCFARLAND\n",
       "49           Willie HANCOCK\n",
       "174            Beryl BURTON\n",
       "175               Ali PATEL\n",
       "665              Rosco SHAH\n",
       "891          Regan FRANKLIN\n",
       "1253            Fannie KOCH\n",
       "1036        Bernadine BOONE\n",
       "243       Krystle RASMUSSEN\n",
       "733            Irena WAGNER\n",
       "1146            Oran HAYNES\n",
       "575            Miracle DUNN\n",
       "1029    Hildegard GILLESPIE\n",
       "915           Shalonda MEZA\n",
       "1131            Tony WAGNER\n",
       "846              Bette MEZA\n",
       "1248             Gregg HOLT\n",
       "499             Lyman RAMOS\n",
       "224            Melody NOLAN\n",
       "277         Milburn PEARSON\n",
       "               ...         \n",
       "60              Young PRATT\n",
       "678         Zita STEPHENSON\n",
       "732             Boss LARSON\n",
       "255         Brennon RICHARD\n",
       "231           Tamra MURILLO\n",
       "441             Danita LEON\n",
       "511          General HERMAN\n",
       "889            Pink MCGRATH\n",
       "963        Yahir PENNINGTON\n",
       "194          Aubrey STEWART\n",
       "297          Afton LAWRENCE\n",
       "737           Ophelia PITTS\n",
       "257            Veda ACEVEDO\n",
       "655          Clarance HEATH\n",
       "694         Maureen SHIELDS\n",
       "1129               Dana ROY\n",
       "710         Shameka PACHECO\n",
       "1068         Ariana BENTLEY\n",
       "260             Iona VARGAS\n",
       "1031          Wendi FISCHER\n",
       "105         Glover MCINTYRE\n",
       "580         Trever MELENDEZ\n",
       "283          Karl VALENTINE\n",
       "894        Mafalda RICHMOND\n",
       "86               James CHOI\n",
       "993           Carmine HODGE\n",
       "1230            Elisha PHAM\n",
       "987       Maritza VELAZQUEZ\n",
       "779          Collette ELLIS\n",
       "1121          Watt GONZALES\n",
       "Name: Name, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "largest_1000_index = np.argsort(aug_LogR_2nd.predict_proba(X_out_sample_1st)[:,1])[-1000:]\n",
    "final_out_sample_1st.iloc[largest_1000_index, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the 1000 called leads, we can derive the expected signups by multiplying the predicted probability in the 1st step modelling by the predicted probability in the 2nd step modelling and then sum up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "441.165410604176"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_out_sample_2nd = final_out_sample_1st.iloc[largest_1000_index, 2:]\n",
    "p1 = LogR.predict_proba(final_out_sample_2nd)[:, 1]\n",
    "p2 = aug_LogR_2nd.predict_proba(final_out_sample_2nd)[:, 1]\n",
    "np.sum(p1*p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected signups is therefore around 564."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finnaly, we want to check by taking all four characteristic features into account, which agent tend to reach more signups in the called leads . We first try to create the predictive model in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_sample = signups_leads_calls_all[(signups_leads_calls_all['Call Outcome'] == 'INTERESTED') | (signups_leads_calls_all['Call Outcome'] == 'NOT INTERESTED')]\n",
    "in_sample_vars = ['Approval Decision', 'Age', 'Sector', 'Region', 'Agent']\n",
    "char_col =  ['Region', 'Sector', 'Agent']\n",
    "char_order = [leadsOrderByRegion.index, leadsOrderBySector.index, signups_rate.index]\n",
    "in_sample_mapper = {'APPROVED':1,\n",
    "                    'REJECTED':1,\n",
    "                    None: 0}\n",
    "\n",
    "final_in_sample = data_pipeline(in_sample, in_sample_vars, 0, char_col, char_order, in_sample_mapper)\n",
    "train_set, test_set = train_test_split(final_in_sample, test_size = 0.2, random_state = 42)\n",
    "train_set = train_set.reset_index(drop = True)\n",
    "test_set = test_set.reset_index(drop = True)\n",
    "\n",
    "X_train = train_set.iloc[:, 1:]\n",
    "Y_train = train_set.iloc[:, 0]\n",
    "X_test = test_set.iloc[:, 1:]\n",
    "Y_test = test_set.iloc[:, 0]\n",
    "X_full = final_in_sample.iloc[:, 1:]\n",
    "Y_full = final_in_sample.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<bound method BaseEstimator.get_params of LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=50, solver='liblinear',\n",
       "           tol=0.0001, verbose=0, warm_start=False)>,\n",
       " <bound method BaseEstimator.get_params of LogisticRegression(C=0.7847599703514611, class_weight=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "           multi_class='warn', n_jobs=None, penalty='l1', random_state=50,\n",
       "           solver='liblinear', tol=0.0001, verbose=0, warm_start=False)>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogR_extended = LogisticRegression(solver= 'liblinear', random_state = 50)\n",
    "\n",
    "param_grid = {'penalty' : ['l1', 'l2'],\n",
    "              'C' : np.logspace(-2, 2, 20),\n",
    "              'class_weight': ['balanced', None],\n",
    "              'solver' : ['liblinear']}\n",
    "temp = LogisticRegression(random_state = 50)\n",
    "grid_search = GridSearchCV(temp, param_grid, cv = 10)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "aug_LogR_extended = grid_search.best_estimator_\n",
    "[LogR_extended.get_params, aug_LogR_extended.get_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  2.2min finished\n"
     ]
    }
   ],
   "source": [
    "RandForest_extended = RandomForestClassifier(n_estimators=100, random_state = 50)\n",
    "\n",
    "temp = RandomForestClassifier(random_state = 50)\n",
    "param_grid = {'n_estimators': [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)],\n",
    "               'max_features': ['auto', 'sqrt'],\n",
    "               'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)],\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "               'min_samples_leaf': [1, 2, 4],\n",
    "               'bootstrap': [True, False]}\n",
    "\n",
    "random_grid = RandomizedSearchCV(estimator = temp, param_distributions = param_grid, n_iter = 50, cv = 5, verbose=2, random_state=50, n_jobs = -1)\n",
    "random_grid.fit(X_train, Y_train)\n",
    "aug_RandForest_extended = random_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=2, min_samples_split=10,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=900, n_jobs=None,\n",
       "            oob_score=False, random_state=50, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict_extended = {'logistic' : LogR_extended, \n",
    "        'tuned logistic' : aug_LogR_extended, \n",
    "        'random forest' : RandForest_extended, \n",
    "        'tuned random forest' : aug_RandForest_extended}\n",
    "\n",
    "validation_dict = {'precision' : precision_score,\n",
    "                  'recall' : recall_score,\n",
    "                   'roc_auc' : roc_auc_score,\n",
    "                  'f1_score': f1_score}\n",
    "\n",
    "\n",
    "LogR_extended.fit(X_train, Y_train)\n",
    "aug_LogR_extended.fit(X_train, Y_train)\n",
    "RandForest_extended.fit(X_train, Y_train)\n",
    "aug_RandForest_extended.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.42712563,  0.34687899,  0.41486207, -0.51101347, -0.15508759,\n",
       "         -0.12175836,  0.08120608, -0.13755526,  0.14506644, -0.4488959 ,\n",
       "         -0.05799832,  0.34300817, -0.37101835,  0.11800854,  0.3667841 ,\n",
       "          0.28667232, -0.80324264, -0.38450747,  1.19576696,  0.32687267,\n",
       "          0.05028557, -0.62173451, -1.39548602]]),\n",
       " array([[-0.23605892,  0.39004618,  0.45149874, -0.43949807, -0.07241232,\n",
       "         -0.04094986,  0.10659246, -0.01978802,  0.08008299, -0.34594331,\n",
       "          0.        ,  0.11790474, -0.5742477 , -0.08331351,  0.1354734 ,\n",
       "          0.05253265, -0.98271527, -0.49401321,  0.88883388,  0.02743826,\n",
       "         -0.19042074, -0.90387519, -1.68697601]])]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[LogR_extended.coef_, aug_LogR_extended.coef_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic</th>\n",
       "      <td>0.565891</td>\n",
       "      <td>0.237398</td>\n",
       "      <td>0.578411</td>\n",
       "      <td>0.334479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuned logistic</th>\n",
       "      <td>0.581301</td>\n",
       "      <td>0.232520</td>\n",
       "      <td>0.579210</td>\n",
       "      <td>0.332172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.377236</td>\n",
       "      <td>0.573870</td>\n",
       "      <td>0.397942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuned random forest</th>\n",
       "      <td>0.535398</td>\n",
       "      <td>0.196748</td>\n",
       "      <td>0.560604</td>\n",
       "      <td>0.287753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     precision    recall   roc_auc  f1_score\n",
       "logistic              0.565891  0.237398  0.578411  0.334479\n",
       "tuned logistic        0.581301  0.232520  0.579210  0.332172\n",
       "random forest         0.421053  0.377236  0.573870  0.397942\n",
       "tuned random forest   0.535398  0.196748  0.560604  0.287753"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_table(model_dict_extended, validation_dict, X_train, Y_train, cross_val_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic</th>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.281046</td>\n",
       "      <td>0.593245</td>\n",
       "      <td>0.375546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuned logistic</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.261438</td>\n",
       "      <td>0.584874</td>\n",
       "      <td>0.355556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>0.346774</td>\n",
       "      <td>0.281046</td>\n",
       "      <td>0.524477</td>\n",
       "      <td>0.310469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuned random forest</th>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.143791</td>\n",
       "      <td>0.543242</td>\n",
       "      <td>0.225641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     precision    recall   roc_auc  f1_score\n",
       "logistic              0.565789  0.281046  0.593245  0.375546\n",
       "tuned logistic        0.555556  0.261438  0.584874  0.355556\n",
       "random forest         0.346774  0.281046  0.524477  0.310469\n",
       "tuned random forest   0.523810  0.143791  0.543242  0.225641"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_table(model_dict_extended, validation_dict, X_test, Y_test, cross_val_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.683798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>red</td>\n",
       "      <td>0.031481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>black</td>\n",
       "      <td>0.026105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>orange</td>\n",
       "      <td>0.020493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>blue</td>\n",
       "      <td>0.019172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>retail</td>\n",
       "      <td>0.015997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>north-west</td>\n",
       "      <td>0.015011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>south-east</td>\n",
       "      <td>0.014789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>food</td>\n",
       "      <td>0.014665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>midlands</td>\n",
       "      <td>0.014558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>south-west</td>\n",
       "      <td>0.013964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>consultancy</td>\n",
       "      <td>0.013186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>wholesale</td>\n",
       "      <td>0.013062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>scotland</td>\n",
       "      <td>0.012692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>north-east</td>\n",
       "      <td>0.012007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>0.012006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>south</td>\n",
       "      <td>0.011436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>construction</td>\n",
       "      <td>0.011363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>london</td>\n",
       "      <td>0.011102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wales</td>\n",
       "      <td>0.009894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>green</td>\n",
       "      <td>0.008372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>northern-ireland</td>\n",
       "      <td>0.007604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>agriculture</td>\n",
       "      <td>0.007244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature  importance\n",
       "0                Age    0.683798\n",
       "19               red    0.031481\n",
       "22             black    0.026105\n",
       "21            orange    0.020493\n",
       "18              blue    0.019172\n",
       "12            retail    0.015997\n",
       "1         north-west    0.015011\n",
       "6         south-east    0.014789\n",
       "13              food    0.014665\n",
       "3           midlands    0.014558\n",
       "2         south-west    0.013964\n",
       "11       consultancy    0.013186\n",
       "14         wholesale    0.013062\n",
       "5           scotland    0.012692\n",
       "4         north-east    0.012007\n",
       "15     entertainment    0.012006\n",
       "7              south    0.011436\n",
       "16      construction    0.011363\n",
       "8             london    0.011102\n",
       "9              wales    0.009894\n",
       "20             green    0.008372\n",
       "10  northern-ireland    0.007604\n",
       "17       agriculture    0.007244"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model = ExtraTreesClassifier(n_estimators = 50)\n",
    "model.fit(X_train, Y_train)\n",
    "importance = pd.Series(model.feature_importances_)\n",
    "features = pd.Series(X_train.columns)\n",
    "importance_table = pd.concat([features, importance], axis = 1)\n",
    "importance_table.columns = ['feature', 'importance']\n",
    "importance_table.sort_values('importance', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is probabily due to the fact that Agents 'red', 'black', 'blue' and 'orange' are all import predictors that the base logistic predicting model has decent precision score. So we can estimate the signups using this one-go predictive model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "blue      2247.0\n",
       "red        839.0\n",
       "green      431.0\n",
       "orange       0.0\n",
       "black        0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_agent = X_full\n",
    "signups_predict = np.zeros(5)\n",
    "Agent = ['blue', 'red', 'green', 'orange', 'black']\n",
    "for i in range(5):\n",
    "    extend = np.zeros(5)\n",
    "    extend[i] = 1\n",
    "    X_agent[Agent] = extend\n",
    "    signups_predict[i] = sum(LogR_extended.predict(X_agent))\n",
    "\n",
    "signups_predict = pd.Series(signups_predict)\n",
    "signups_predict.index = Agent\n",
    "signups_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# becuase the forecasting performance of one go modelling is not convincing, we are now switching to two-step modelling method.\n",
    "# 1st step starts\n",
    "in_sample = signups_leads_calls_all[(signups_leads_calls_all['Call Outcome'] == 'INTERESTED') | (signups_leads_calls_all['Call Outcome'] == 'NOT INTERESTED')]\n",
    "in_sample_vars = ['Call Outcome', 'Age', 'Sector', 'Region', 'Agent']\n",
    "char_col =  ['Region', 'Sector', 'Agent']\n",
    "char_order = [leadsOrderByRegion.index, leadsOrderBySector.index, signups_rate.index]\n",
    "in_sample_mapper = {'INTERESTED':1, 'NOT INTERESTED':0}\n",
    "out_sample_mapper = {}\n",
    "\n",
    "final_in_sample = data_pipeline(in_sample, in_sample_vars, 0, char_col, char_order, in_sample_mapper)\n",
    "train_set, test_set = train_test_split(final_in_sample, test_size = 0.2, random_state = 42)\n",
    "train_set = train_set.reset_index(drop = True)\n",
    "test_set = test_set.reset_index(drop = True)\n",
    "\n",
    "X_train = train_set.iloc[:, 1:]\n",
    "Y_train = train_set.iloc[:, 0]\n",
    "X_test = test_set.iloc[:, 1:]\n",
    "Y_test = test_set.iloc[:, 0]\n",
    "X_full = final_in_sample.iloc[:, 1:]\n",
    "Y_full = final_in_sample.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<bound method BaseEstimator.get_params of LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=50, solver='liblinear',\n",
       "           tol=0.0001, verbose=0, warm_start=False)>,\n",
       " <bound method BaseEstimator.get_params of LogisticRegression(C=0.29763514416313175, class_weight='balanced', dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "           multi_class='warn', n_jobs=None, penalty='l1', random_state=50,\n",
       "           solver='liblinear', tol=0.0001, verbose=0, warm_start=False)>]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogR_extended = LogisticRegression(solver= 'liblinear', random_state=50)\n",
    "\n",
    "param_grid = {\n",
    "     'penalty' : ['l1', 'l2'],\n",
    "    'C' : np.logspace(-2, 2, 20),\n",
    "    'class_weight': ['balanced', None],\n",
    "    'solver' : ['liblinear']}\n",
    "temp = LogisticRegression(random_state = 50)\n",
    "grid_search = GridSearchCV(temp, param_grid, cv = 10)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "aug_LogR_extended = grid_search.best_estimator_\n",
    "[LogR_extended.get_params, aug_LogR_extended.get_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  2.2min finished\n"
     ]
    }
   ],
   "source": [
    "RandForest_extended = RandomForestClassifier(n_estimators=100, random_state = 50)\n",
    "\n",
    "temp = RandomForestClassifier(random_state = 50)\n",
    "param_grid = {'n_estimators': [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)],\n",
    "               'max_features': ['auto', 'sqrt'],\n",
    "               'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)],\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "               'min_samples_leaf': [1, 2, 4],\n",
    "               'bootstrap': [True, False]}\n",
    "\n",
    "random_grid = RandomizedSearchCV(estimator = temp, param_distributions = param_grid, n_iter = 50, cv = 5, verbose=2, random_state=50, n_jobs = -1)\n",
    "random_grid.fit(X_train, Y_train)\n",
    "aug_RandForest_extended = random_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-5.23481611e-01,  6.10970594e-01,  4.46955690e-01,\n",
       "         -6.52963170e-01, -2.38301838e-01, -2.41456166e-01,\n",
       "         -2.29392503e-02, -1.08240604e-01,  1.54029661e+00,\n",
       "         -7.56019513e-01, -2.82139524e-01,  8.56037270e-01,\n",
       "         -5.70099167e-01,  1.18084234e-04,  5.85866462e-01,\n",
       "          2.62702941e-01, -8.01872075e-01, -3.65906927e-02,\n",
       "          9.51754724e-01,  2.70244784e-01,  7.21251771e-02,\n",
       "         -2.46117045e-01, -7.51844818e-01]]),\n",
       " array([[ 0.        ,  0.74078937,  0.55516255, -0.4253809 ,  0.        ,\n",
       "         -0.00491947,  0.0782384 ,  0.        ,  1.43939271, -0.45003213,\n",
       "          0.        ,  0.78998769, -0.55152453,  0.        ,  0.5101017 ,\n",
       "          0.17245713, -0.6896387 ,  0.        ,  0.65096251,  0.16637206,\n",
       "          0.        , -0.28616908, -0.76282779]])]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict_extend = {'logistic' : LogR_extended, \n",
    "        'tuned logistic' : aug_LogR_extended, \n",
    "        'random forest' : RandForest_extended, \n",
    "        'tuned random forest' : aug_RandForest_extended}\n",
    "\n",
    "validation_dict = {'precision' : precision_score,\n",
    "                  'recall' : recall_score,\n",
    "                   'roc_auc' : roc_auc_score,\n",
    "                  'f1_score': f1_score}\n",
    "\n",
    "LogR_extended.fit(X_train, Y_train)\n",
    "aug_LogR_extended.fit(X_train, Y_train)\n",
    "RandForest_extended.fit(X_train, Y_train)\n",
    "aug_RandForest_extended.fit(X_train, Y_train)\n",
    "\n",
    "[LogR_extended.coef_, aug_LogR_extended.coef_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic</th>\n",
       "      <td>0.663850</td>\n",
       "      <td>0.675908</td>\n",
       "      <td>0.651301</td>\n",
       "      <td>0.669825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuned logistic</th>\n",
       "      <td>0.664767</td>\n",
       "      <td>0.669216</td>\n",
       "      <td>0.650562</td>\n",
       "      <td>0.666984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>0.603561</td>\n",
       "      <td>0.615679</td>\n",
       "      <td>0.587297</td>\n",
       "      <td>0.609560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuned random forest</th>\n",
       "      <td>0.642534</td>\n",
       "      <td>0.678776</td>\n",
       "      <td>0.633444</td>\n",
       "      <td>0.660158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     precision    recall   roc_auc  f1_score\n",
       "logistic              0.663850  0.675908  0.651301  0.669825\n",
       "tuned logistic        0.664767  0.669216  0.650562  0.666984\n",
       "random forest         0.603561  0.615679  0.587297  0.609560\n",
       "tuned random forest   0.642534  0.678776  0.633444  0.660158"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_table(model_dict_extended, validation_dict, X_train, Y_train, cross_val_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic</th>\n",
       "      <td>0.644628</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.641365</td>\n",
       "      <td>0.634146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuned logistic</th>\n",
       "      <td>0.640496</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.637381</td>\n",
       "      <td>0.630081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>0.511719</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.513984</td>\n",
       "      <td>0.517787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuned random forest</th>\n",
       "      <td>0.601660</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.599524</td>\n",
       "      <td>0.590631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     precision  recall   roc_auc  f1_score\n",
       "logistic              0.644628   0.624  0.641365  0.634146\n",
       "tuned logistic        0.640496   0.620  0.637381  0.630081\n",
       "random forest         0.511719   0.524  0.513984  0.517787\n",
       "tuned random forest   0.601660   0.580  0.599524  0.590631"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_table(model_dict_extended, validation_dict, X_test, Y_test, cross_val_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the base logistic model outperforms the rest, we shall use the base logistic model for the 1st step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_agent = X_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd step \n",
    "in_sample = signups_leads_calls_all[(signups_leads_calls_all['Call Outcome'] == 'INTERESTED')]\n",
    "in_sample_vars = ['Approval Decision', 'Age', 'Sector', 'Region', 'Agent']\n",
    "char_col =  ['Region', 'Sector', 'Agent']\n",
    "char_order = [leadsOrderByRegion.index, leadsOrderBySector.index, signups_rate.index]\n",
    "in_sample_mapper = {'APPROVED':1, 'REJECTED':1, None:0}\n",
    "final_in_sample_extended = data_pipeline(in_sample, in_sample_vars, 0, char_col, char_order, in_sample_mapper)\n",
    "train_set, test_set = train_test_split(final_in_sample_extended, test_size = 0.2, random_state = 42)\n",
    "train_set.reset_index(drop = True)\n",
    "test_set.reset_index(drop = True)\n",
    "X_train = train_set.iloc[:, 1:]\n",
    "Y_train = train_set.iloc[:, 0]\n",
    "X_test = test_set.iloc[:, 1:]\n",
    "Y_test = test_set.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<bound method BaseEstimator.get_params of LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "           tol=0.0001, verbose=0, warm_start=False)>,\n",
       " <bound method BaseEstimator.get_params of LogisticRegression(C=0.1623776739188721, class_weight=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "           multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
       "           solver='liblinear', tol=0.0001, verbose=0, warm_start=False)>]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "LogR_extended_2nd = LogisticRegression(solver= 'liblinear')\n",
    "\n",
    "param_grid = {\n",
    "     'penalty' : ['l1', 'l2'],\n",
    "    'C' : np.logspace(-5, 5, 20),\n",
    "    'class_weight': ['balanced', None],\n",
    "    'solver' : ['liblinear']}\n",
    "temp = LogisticRegression()\n",
    "grid_search = GridSearchCV(temp, param_grid, cv = 10)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "aug_LogR_extended_2nd = grid_search.best_estimator_\n",
    "[LogR_extended_2nd.get_params, aug_LogR_extended_2nd.get_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  2.8min finished\n"
     ]
    }
   ],
   "source": [
    "RandForest_extended_2nd = RandomForestClassifier(n_estimators=100, random_state = 50)\n",
    "\n",
    "temp = RandomForestClassifier(random_state = 50)\n",
    "param_grid = {'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)],\n",
    "               'max_features': ['auto', 'sqrt'],\n",
    "               'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)],\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "               'min_samples_leaf': [1, 2, 4],\n",
    "               'bootstrap': [True, False]}\n",
    "\n",
    "random_grid = RandomizedSearchCV(estimator = temp, param_distributions = param_grid, n_iter = 50, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "random_grid.fit(X_train, Y_train)\n",
    "aug_RandForest_extended_2nd = random_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<bound method BaseEstimator.get_params of RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "             oob_score=False, random_state=50, verbose=0, warm_start=False)>,\n",
       " <bound method BaseEstimator.get_params of LogisticRegression(C=0.1623776739188721, class_weight=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "           multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
       "           solver='liblinear', tol=0.0001, verbose=0, warm_start=False)>]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[RandForest_extended_2nd.get_params, aug_LogR_extended_2nd.get_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.11904204,  0.04746577,  0.48058017,  0.05188084,  0.04688377,\n",
       "          0.13318816,  0.11924707, -0.17678567, -0.50970723,  0.11895485,\n",
       "         -0.02726972,  0.01400882,  0.2573736 ,  0.50388326,  0.30642185,\n",
       "          0.04997604, -0.2367378 , -0.61048776,  1.13587193,  0.61848788,\n",
       "          0.18898966, -0.52842011, -1.13049135]]),\n",
       " array([[-3.10153927e-02,  3.15613020e-02,  3.80964350e-01,\n",
       "          3.74313613e-02,  4.41789673e-02,  9.81670613e-02,\n",
       "          8.30915176e-02, -1.44597983e-01, -3.34894213e-01,\n",
       "          8.95175111e-02, -2.92974080e-02, -3.94551437e-02,\n",
       "          1.89561517e-01,  4.15006834e-01,  2.25424369e-01,\n",
       "         -2.94870884e-04, -1.63507057e-01, -3.70613181e-01,\n",
       "          7.25735243e-01,  6.39111781e-01,  1.99517177e-01,\n",
       "         -4.18148767e-01, -8.90092966e-01]])]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict_extended_2nd = {'logistic extended 2nd':LogR_extended_2nd, \n",
    "        'tuned logistic extended 2nd':aug_LogR_extended_2nd, \n",
    "        'random forest extended 2nd':RandForest_extended_2nd, \n",
    "        'tuned random forest extended 2nd':aug_RandForest_extended_2nd}\n",
    "\n",
    "LogR_extended_2nd.fit(X_train, Y_train)\n",
    "aug_LogR_extended_2nd.fit(X_train, Y_train)\n",
    "RandForest_extended_2nd.fit(X_train, Y_train)\n",
    "aug_RandForest_extended_2nd.fit(X_train, Y_train)\n",
    "\n",
    "[LogR_extended_2nd.coef_, aug_LogR_extended_2nd.coef_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic extended 2nd</th>\n",
       "      <td>0.676838</td>\n",
       "      <td>0.785829</td>\n",
       "      <td>0.612192</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuned logistic extended 2nd</th>\n",
       "      <td>0.676630</td>\n",
       "      <td>0.801932</td>\n",
       "      <td>0.614219</td>\n",
       "      <td>0.733972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest extended 2nd</th>\n",
       "      <td>0.652106</td>\n",
       "      <td>0.673108</td>\n",
       "      <td>0.567879</td>\n",
       "      <td>0.662441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuned random forest extended 2nd</th>\n",
       "      <td>0.662011</td>\n",
       "      <td>0.763285</td>\n",
       "      <td>0.590076</td>\n",
       "      <td>0.709050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  precision    recall   roc_auc  f1_score\n",
       "logistic extended 2nd              0.676838  0.785829  0.612192  0.727273\n",
       "tuned logistic extended 2nd        0.676630  0.801932  0.614219  0.733972\n",
       "random forest extended 2nd         0.652106  0.673108  0.567879  0.662441\n",
       "tuned random forest extended 2nd   0.662011  0.763285  0.590076  0.709050"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_table(model_dict_extended_2nd, validation_dict, X_train, Y_train, cross_val_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic extended 2nd</th>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.789116</td>\n",
       "      <td>0.611372</td>\n",
       "      <td>0.709480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuned logistic extended 2nd</th>\n",
       "      <td>0.646409</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.614773</td>\n",
       "      <td>0.713415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest extended 2nd</th>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.639456</td>\n",
       "      <td>0.571940</td>\n",
       "      <td>0.632997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuned random forest extended 2nd</th>\n",
       "      <td>0.670659</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.637590</td>\n",
       "      <td>0.713376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  precision    recall   roc_auc  f1_score\n",
       "logistic extended 2nd              0.644444  0.789116  0.611372  0.709480\n",
       "tuned logistic extended 2nd        0.646409  0.795918  0.614773  0.713415\n",
       "random forest extended 2nd         0.626667  0.639456  0.571940  0.632997\n",
       "tuned random forest extended 2nd   0.670659  0.761905  0.637590  0.713376"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_table(model_dict_extended_2nd, validation_dict, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run regression to see the predicted leads for each agent by setting each of the agent to be 1 and dropping the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "blue      2312.0\n",
       "red       1756.0\n",
       "green     1599.0\n",
       "orange     526.0\n",
       "black      116.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signups_predict = np.zeros(5)\n",
    "Agent = ['blue', 'red', 'green', 'orange', 'black']\n",
    "\n",
    "for i in range(5):\n",
    "    extend = np.zeros(5)\n",
    "    extend[i] = 1\n",
    "    X_agent[Agent] = extend \n",
    "    selected_index = X_agent.index[LogR_extended.predict(X_agent) == 1].tolist()\n",
    "    X_in_sample = X_agent.iloc[selected_index, :]\n",
    "    signups_predict[i] = sum(aug_RandForest_extended_2nd.predict(X_in_sample))\n",
    "\n",
    "signups_predict = pd.Series(signups_predict)\n",
    "signups_predict.index = Agent\n",
    "signups_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the 2-step modelling method is more appropriate, I shall use the 2-step modelling method to estimata the signups for each agent for the 1000 selected leads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "blue      704.531561\n",
       "red       600.753574\n",
       "green     538.084104\n",
       "orange    492.374353\n",
       "black     270.076941\n",
       "dtype: float64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_agent = final_out_sample_2nd.reset_index(drop=True)\n",
    "X_agent['blue'] = 0\n",
    "X_agent['red'] = 0\n",
    "X_agent['green'] = 0\n",
    "X_agent['orange'] = 0\n",
    "X_agent['black'] = 0\n",
    "\n",
    "X_agent = X_agent.reset_index(drop = True)\n",
    "for i in range(5):\n",
    "    extend = np.zeros(5)\n",
    "    extend[i] = 1\n",
    "    X_agent[Agent] = extend \n",
    "    selected_index = X_agent.index[LogR_extended.predict(X_agent) == 1].tolist()\n",
    "    X = X_agent.iloc[selected_index, :]\n",
    "    pr1 = LogR_extended.predict_proba(X)\n",
    "    pr2 = aug_RandForest_extended_2nd.predict_proba(X)\n",
    "    signups_predict[i] = np.sum(pr1 * pr2)\n",
    "\n",
    "signups_predict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
